{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Guillaume Thibault 1948612\n",
        "\n",
        "Julien Witty 1949837"
      ],
      "metadata": {
        "id": "PaK_9zqczyHS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tmOFPR8VmUq"
      },
      "source": [
        "# Machine translation\n",
        "\n",
        "The goal of this TP is to build a machine translation model.\n",
        "You will be comparing the performance of three different architectures:\n",
        "* A vanilla RNN\n",
        "* A GRU-RNN\n",
        "* A transformer\n",
        "\n",
        "You are provided with the code to load and build the pytorch dataset,\n",
        "and the code for the training loop.\n",
        "You \"only\" have to code the architectures.\n",
        "Of course, the use of built-in torch layers such as `nn.GRU`, `nn.RNN` or `nn.Transformer`\n",
        "is forbidden, as there would be no exercise otherwise.\n",
        "\n",
        "The source sentences are in english and the target language is french.\n",
        "\n",
        "This is also for you the occasion to see what a basic machine learning pipeline looks like.\n",
        "Take a look at the given code, you might learn a lot!\n",
        "\n",
        "Do not forget to **select the runtime type as GPU!**\n",
        "\n",
        "**Sources**\n",
        "\n",
        "* Dataset: [Tab-delimited Bilingual Sentence Pairs](http://www.manythings.org/anki/)\n",
        "\n",
        "<!---\n",
        "M. Cettolo, C. Girardi, and M. Federico. 2012. WIT3: Web Inventory of Transcribed and Translated Talks. In Proc. of EAMT, pp. 261-268, Trento, Italy. pdf, bib. [paper](https://aclanthology.org/2012.eamt-1.60.pdf). [website](https://wit3.fbk.eu/2016-01).\n",
        "-->\n",
        "\n",
        "* The code is inspired by this [pytorch tutorial](https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html).\n",
        "\n",
        "*This notebook is quite big, use the table of contents to easily navigate through it.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyCdlapMV8Hu"
      },
      "source": [
        "# Imports and data initializations\n",
        "\n",
        "We first download and parse the dataset. From the parsed sentences\n",
        "we can build the vocabularies and the torch datasets.\n",
        "The end goal of this section is to have an iterator\n",
        "that can yield the pairs of translated datasets, and\n",
        "where each sentences is made of a sequence of tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "vLbVbH4lu4J0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJQfREvFUdoz"
      },
      "outputs": [],
      "source": [
        "!python3 -m spacy download en > /dev/null\n",
        "!python3 -m spacy download fr > /dev/null\n",
        "!pip install torchinfo > /dev/null\n",
        "!pip install einops > /dev/null\n",
        "!pip install wandb > /dev/null\n",
        "\n",
        "\n",
        "from itertools import takewhile\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator, Vocab\n",
        "from torchtext.datasets import IWSLT2016\n",
        "\n",
        "import einops\n",
        "import wandb\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tokenizers are objects that are able to divide a python string into a list of tokens (words, punctuations, special tokens...) as a list of strings.\n",
        "\n",
        "The special tokens are used for a particular reasons:\n",
        "* *\\<unk\\>*: Replace an unknown word in the vocabulary by this default token\n",
        "* *\\<pad\\>*: Virtual token used to as padding token so a batch of sentences can have a unique length\n",
        "* *\\<bos\\>*: Token indicating the beggining of a sentence in the target sequence\n",
        "* *\\<eos\\>*: Token indicating the end of a sentence in the target sequence"
      ],
      "metadata": {
        "id": "ppPj9CrnsSoW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxNpMbkvUfGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7dccebf-01d4-4580-a8e0-f5118375bbeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-12 02:58:02--  http://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.21.92.44, 172.67.186.54, 2606:4700:3030::6815:5c2c, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.21.92.44|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6532197 (6.2M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip.1’\n",
            "\n",
            "\rfra-eng.zip.1         0%[                    ]       0  --.-KB/s               \rfra-eng.zip.1       100%[===================>]   6.23M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-04-12 02:58:02 (120 MB/s) - ‘fra-eng.zip.1’ saved [6532197/6532197]\n",
            "\n",
            "Archive:  fra-eng.zip\n",
            "replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "173106\n"
          ]
        }
      ],
      "source": [
        "# Original dataset, but there's a bug on Colab with it\n",
        "# train, valid, _ = IWSLT2016(language_pair=('fr', 'en'))\n",
        "# train, valid = list(train), list(valid)\n",
        "\n",
        "# Another dataset, but it is too huge\n",
        "# !wget https://www.statmt.org/wmt14/training-monolingual-europarl-v7/europarl-v7.en.gz\n",
        "# !wget https://www.statmt.org/wmt14/training-monolingual-europarl-v7/europarl-v7.fr.gz\n",
        "# !gunzip europarl-v7.en.gz\n",
        "# !gunzip europarl-v7.fr.gz\n",
        "\n",
        "# with open('europarl-v7.en', 'r') as my_file:\n",
        "#     english = my_file.readlines()\n",
        "\n",
        "# with open('europarl-v7.fr', 'r') as my_file:\n",
        "#     french = my_file.readlines()\n",
        "\n",
        "# dataset = [\n",
        "#     (en, fr)\n",
        "#     for en, fr in zip(english, french)\n",
        "# ]\n",
        "# print(f'\\n{len(dataset):,} sentences.')\n",
        "\n",
        "# dataset, _ = train_test_split(dataset, test_size=0.8, random_state=0)  # Remove 80% of the dataset (it would be huge otherwise)\n",
        "# train, valid = train_test_split(dataset, test_size=0.2, random_state=0)  # Split between train and validation dataset\n",
        "\n",
        "# Our current dataset\n",
        "!wget http://www.manythings.org/anki/fra-eng.zip\n",
        "!unzip fra-eng.zip\n",
        "\n",
        "\n",
        "df = pd.read_csv('fra.txt', sep='\\t', names=['english', 'french', 'attribution'])\n",
        "train = [\n",
        "    (en, fr) for en, fr in zip(df['english'], df['french'])\n",
        "]\n",
        "train, valid = train_test_split(train, test_size=0.1, random_state=0)\n",
        "print(len(train))\n",
        "\n",
        "en_tokenizer, fr_tokenizer = get_tokenizer('spacy', language='en'), get_tokenizer('spacy', language='fr')\n",
        "\n",
        "SPECIALS = ['<unk>', '<pad>', '<bos>', '<eos>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ddZvN5FiK9u"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "Functions and classes to build the vocabularies and the torch datasets.\n",
        "The vocabulary is an object able to transform a string token into the id (an int) of that token in the vocabulary. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2dKQ6PvZC_U"
      },
      "outputs": [],
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            dataset: list,\n",
        "            en_vocab: Vocab,\n",
        "            fr_vocab: Vocab,\n",
        "            en_tokenizer,\n",
        "            fr_tokenizer,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dataset = dataset\n",
        "        self.en_vocab = en_vocab\n",
        "        self.fr_vocab = fr_vocab\n",
        "        self.en_tokenizer = en_tokenizer\n",
        "        self.fr_tokenizer = fr_tokenizer\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of examples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index: int) -> tuple:\n",
        "        \"\"\"Return a sample.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            index: Index of the sample.\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            en_tokens: English tokens of the sample, as a LongTensor.\n",
        "            fr_tokens: French tokens of the sample, as a LongTensor.\n",
        "        \"\"\"\n",
        "        # Get the strings\n",
        "        en_sentence, fr_sentence = self.dataset[index]\n",
        "\n",
        "        # To list of words\n",
        "        # We also add the beggining-of-sentence and end-of-sentence tokens\n",
        "        en_tokens = ['<bos>'] + self.en_tokenizer(en_sentence) + ['<eos>']\n",
        "        fr_tokens = ['<bos>'] + self.fr_tokenizer(fr_sentence) + ['<eos>']\n",
        "\n",
        "        # To list of tokens\n",
        "        en_tokens = self.en_vocab(en_tokens)  # list[int]\n",
        "        fr_tokens = self.fr_vocab(fr_tokens)\n",
        "\n",
        "        return torch.LongTensor(en_tokens), torch.LongTensor(fr_tokens)\n",
        "\n",
        "\n",
        "def yield_tokens(dataset, tokenizer, lang):\n",
        "    \"\"\"Tokenize the whole dataset and yield the tokens.\n",
        "    \"\"\"\n",
        "    assert lang in ('en', 'fr')\n",
        "    sentence_idx = 0 if lang == 'en' else 1\n",
        "\n",
        "    for sentences in dataset:\n",
        "        sentence = sentences[sentence_idx]\n",
        "        tokens = tokenizer(sentence)\n",
        "        yield tokens\n",
        "\n",
        "\n",
        "def build_vocab(dataset: list, en_tokenizer, fr_tokenizer, min_freq: int):\n",
        "    \"\"\"Return two vocabularies, one for each language.\n",
        "    \"\"\"\n",
        "    en_vocab = build_vocab_from_iterator(\n",
        "        yield_tokens(dataset, en_tokenizer, 'en'),\n",
        "        min_freq=min_freq,\n",
        "        specials=SPECIALS,\n",
        "    )\n",
        "    en_vocab.set_default_index(en_vocab['<unk>'])  # Default token for unknown words\n",
        "\n",
        "    fr_vocab = build_vocab_from_iterator(\n",
        "        yield_tokens(dataset, fr_tokenizer, 'fr'),\n",
        "        min_freq=min_freq,\n",
        "        specials=SPECIALS,\n",
        "    )\n",
        "    fr_vocab.set_default_index(fr_vocab['<unk>'])\n",
        "\n",
        "    return en_vocab, fr_vocab\n",
        "\n",
        "\n",
        "def preprocess(\n",
        "        dataset: list,\n",
        "        en_tokenizer,\n",
        "        fr_tokenizer,\n",
        "        max_words: int,\n",
        "    ) -> list:\n",
        "    \"\"\"Preprocess the dataset.\n",
        "    Remove samples where at least one of the sentences are too long.\n",
        "    Those samples takes too much memory.\n",
        "    Also remove the pending '\\n' at the end of sentences.\n",
        "    \"\"\"\n",
        "    filtered = []\n",
        "\n",
        "    for en_s, fr_s in dataset:\n",
        "        if len(en_tokenizer(en_s)) >= max_words or len(fr_tokenizer(fr_s)) >= max_words:\n",
        "            continue\n",
        "        \n",
        "        en_s = en_s.replace('\\n', '')\n",
        "        fr_s = fr_s.replace('\\n', '')\n",
        "\n",
        "        filtered.append((en_s, fr_s))\n",
        "\n",
        "    return filtered\n",
        "\n",
        "\n",
        "def build_datasets(\n",
        "        max_sequence_length: int,\n",
        "        min_token_freq: int,\n",
        "        en_tokenizer,\n",
        "        fr_tokenizer,\n",
        "        train: list,\n",
        "        val: list,\n",
        "    ) -> tuple:\n",
        "    \"\"\"Build the training, validation and testing datasets.\n",
        "    It takes care of the vocabulary creation.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        - max_sequence_length: Maximum number of tokens in each sequences.\n",
        "            Having big sequences increases dramatically the VRAM taken during training.\n",
        "        - min_token_freq: Minimum number of occurences each token must have\n",
        "            to be saved in the vocabulary. Reducing this number increases\n",
        "            the vocabularies's size.\n",
        "        - en_tokenizer: Tokenizer for the english sentences.\n",
        "        - fr_tokenizer: Tokenizer for the french sentences.\n",
        "        - train and val: List containing the pairs (english, french) sentences.\n",
        "\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        - (train_dataset, val_dataset): Tuple of the two TranslationDataset objects.\n",
        "    \"\"\"\n",
        "    datasets = [\n",
        "        preprocess(samples, en_tokenizer, fr_tokenizer, max_sequence_length)\n",
        "        for samples in [train, val]\n",
        "    ]\n",
        "\n",
        "    en_vocab, fr_vocab = build_vocab(datasets[0], en_tokenizer, fr_tokenizer, min_token_freq)\n",
        "\n",
        "    datasets = [\n",
        "        TranslationDataset(samples, en_vocab, fr_vocab, en_tokenizer, fr_tokenizer)\n",
        "        for samples in datasets\n",
        "    ]\n",
        "\n",
        "    return datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWlH-qEbkoYA"
      },
      "outputs": [],
      "source": [
        "def generate_batch(data_batch: list, src_pad_idx: int, tgt_pad_idx: int) -> tuple:\n",
        "    \"\"\"Add padding to the given batch so that all\n",
        "    the samples are of the same size.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        data_batch: List of samples.\n",
        "            Each sample is a tuple of LongTensors of varying size.\n",
        "        src_pad_idx: Source padding index value.\n",
        "        tgt_pad_idx: Target padding index value.\n",
        "    \n",
        "    Output\n",
        "    ------\n",
        "        en_batch: Batch of tokens for the padded english sentences.\n",
        "            Shape of [batch_size, max_en_len].\n",
        "        fr_batch: Batch of tokens for the padded french sentences.\n",
        "            Shape of [batch_size, max_fr_len].\n",
        "    \"\"\"\n",
        "    en_batch, fr_batch = [], []\n",
        "    for en_tokens, fr_tokens in data_batch:\n",
        "        en_batch.append(en_tokens)\n",
        "        fr_batch.append(fr_tokens)\n",
        "\n",
        "    en_batch = pad_sequence(en_batch, padding_value=src_pad_idx, batch_first=True)\n",
        "    fr_batch = pad_sequence(fr_batch, padding_value=tgt_pad_idx, batch_first=True)\n",
        "    return en_batch, fr_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8Gs4Myjh-jV"
      },
      "source": [
        "# Models architecture\n",
        "This is where you have to code the architectures.\n",
        "\n",
        "In a machine translation task, the model takes as input the whole\n",
        "source sentence along with the current known tokens of the target,\n",
        "and predict the next token in the target sequence.\n",
        "This means that the target tokens are predicted in an autoregressive\n",
        "manner, starting from the first token (right after the *\\<bos\\>* token) and producing tokens one by one until the last *\\<eos\\>* token.\n",
        "\n",
        "Formally, we define $s = [s_1, ..., s_{N_s}]$ as the source sequence made of $N_s$ tokens.\n",
        "We also define $t^i = [t_1, ..., t_i]$ as the target sequence at the beginning of the step $i$.\n",
        "\n",
        "The output of the model parameterized by $\\theta$ is:\n",
        "\n",
        "$$\n",
        "T_{i+1} = p(t_{i+1} | s, t^i ; \\theta )\n",
        "$$\n",
        "\n",
        "Where $T_{i+1}$ is the distribution of the next token $t_{i+1}$.\n",
        "\n",
        "The loss is simply a *cross entropy loss* over the whole steps, where each class is a token of the vocabulary.\n",
        "\n",
        "![RNN schema for machinea translation](https://www.simplilearn.com/ice9/free_resources_article_thumb/machine-translation-model-with-encoder-decoder-rnn.jpg)\n",
        "\n",
        "Note that in this image the english sentence is provided in reverse. \n",
        "\n",
        "---\n",
        "\n",
        "In pytorch, there is no dinstinction between an intermediate layer or a whole model having multiple layers in itself.\n",
        "Every layers or models inherit from the `torch.nn.Module`.\n",
        "This module needs to define the `__init__` method where you instanciate the layers,\n",
        "and the `forward` method where you decide how the inputs and the layers of the module interact between them.\n",
        "Thanks to the autograd computations of pytorch, you do not have\n",
        "to implement any backward method!\n",
        "\n",
        "A really important advice is to **always look at\n",
        "the shape of your input and your output.**\n",
        "From that, you can often guess how the layers should interact\n",
        "with the inputs to produce the right output.\n",
        "You can also easily detect if there's something wrong going on.\n",
        "\n",
        "You are more than advised to use the `einops` library and the `torch.einsum` function. This will require less operations than 'classical' code, but note that it's a bit trickier to use.\n",
        "This is a way of describing tensors manipulation with strings, bypassing the multiple tensor methods executed in the background.\n",
        "You can find a nice presentation of `einops` [here](https://einops.rocks/1-einops-basics/).\n",
        "A paper has just been released about einops [here](https://paperswithcode.com/paper/einops-clear-and-reliable-tensor).\n",
        "\n",
        "**A great tutorial on pytorch can be found [here](https://stanford.edu/class/cs224n/materials/CS224N_PyTorch_Tutorial.html).**\n",
        "Spending 3 hours on this tutorial is *no* waste of time."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN models"
      ],
      "metadata": {
        "id": "xodRThXg2DHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN\n",
        "Here you have to implement a recurrent neural network. You will need to create a single RNN Layer, and a module allowing to stack these layers. Look up the pytorch documentation to figure out this module's operations and what is communicated from one layer to another.\n",
        "\n",
        "The `RNNCell` layer produce one hidden state vector for each sentence in the batch\n",
        "(useful for the output of the encoder), and also produce one embedding for each\n",
        "token in each sentence (useful for the output of the decoder).\n",
        "\n",
        "The `RNN` module is composed of a stack of `RNNCell`. Each token embeddings\n",
        "coming out from a previous `RNNCell` is used as an input for the next `RNNCell` layer.\n",
        "\n",
        "**Be careful !** Our `RNNCell` implementation is not exactly the same thing as\n",
        "the PyTorch's `nn.RNNCell`. PyTorch implements only the operations for one token\n",
        "(so you would need to loop through each tokens inside the `RNN` instead).\n",
        "You are free to implement `RNN` and `RNNCell` the way you want, as long as it has the expected behaviour of a RNN.\n",
        "\n",
        "The same thing apply for the `GRU` and `GRUCell`.\n"
      ],
      "metadata": {
        "id": "ZvfRVUKm1u8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
        "import copy\n",
        "def clones(module, N):\n",
        "    \"Produce N identical layers.\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ],
      "metadata": {
        "id": "KaW7Rxvn85KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import rearrange, reduce, repeat\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class RNNCell(nn.Module):\n",
        "    \"\"\"A single RNN layer.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "        input_size: Size of each input token.\n",
        "        hidden_size: Size of each RNN hidden state.\n",
        "        dropout: Dropout rate.\n",
        "\n",
        "    Important note: This layer does not exactly the same thing as nn.RNNCell does.\n",
        "    PyTorch implementation is only doing one simple pass over one token for each batch.\n",
        "    This implementation is taking the whole sequence of each batch and provide the\n",
        "    final hidden state along with the embeddings of each token in each sequence.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size: int,\n",
        "            hidden_size: int,\n",
        "            dropout: float,\n",
        "        ):\n",
        "        super().__init__() \n",
        "\n",
        "        self.Wi = nn.Linear(input_size, hidden_size).to(device)\n",
        "        self.Wh = nn.Linear(hidden_size, hidden_size).to(device)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.FloatTensor, h: torch.FloatTensor) -> tuple:\n",
        "        \"\"\"Go through all the sequence in x, iteratively updating\n",
        "        the hidden state h.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            x: Input sequence.\n",
        "                Shape of [batch_size, seq_len, input_size].\n",
        "            h: Initial hidden state.\n",
        "                Shape of [batch_size, hidden_size].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            y: Token embeddings.\n",
        "                Shape of [batch_size, seq_len, hidden_size].\n",
        "            h: Last hidden state.\n",
        "                Shape of [batch_size, hidden_size].\n",
        "        \"\"\"\n",
        "        x = rearrange(x, 'b s i -> s b i')\n",
        "        y = torch.zeros((x.shape[0], x.shape[1], h.shape[1])).to(x.device)\n",
        "        for i, seq in enumerate(x):\n",
        "          # [b h]        [i,h] [b,i]    [h,h] [b,h]\n",
        "          h = torch.tanh(self.Wi(seq) + self.Wh(h))\n",
        "          h = self.dropout(h)\n",
        "          y[i] = h\n",
        "\n",
        "        y = rearrange(y, 's b h -> b s h')\n",
        "\n",
        "        return y, h\n",
        "\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    \"\"\"Implementation of an RNN based\n",
        "    on https://pytorch.org/docs/stable/generated/torch.nn.RNN.html.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        input_size: Size of each input token.\n",
        "        hidden_size: Size of each RNN hidden state.\n",
        "        num_layers: Number of layers (RNNCell or GRUCell).\n",
        "        dropout: Dropout rate.\n",
        "        model_type: Either 'RNN' or 'GRU', to select which model we want.\n",
        "            This parameter can be removed if you decide to use the module `GRU`.\n",
        "            Indeed, `GRU` should have exactly the same code as this module,\n",
        "            but with `GRUCell` instead of `RNNCell`. We let the freedom for you\n",
        "            to decide at which level you want to specialise the modules (either\n",
        "            in `TranslationRNN` by creating a `GRU` or a `RNN`, or in `RNN`\n",
        "            by creating a `GRUCell` or a `RNNCell`).\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size: int,\n",
        "            hidden_size: int,\n",
        "            num_layers: int,\n",
        "            dropout: float,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Model\n",
        "        self.layers = nn.ModuleList([RNNCell(input_size, hidden_size, dropout)])\n",
        "        self.layers.extend(clones(RNNCell(hidden_size, hidden_size, dropout), num_layers-1))\n",
        "\n",
        "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x: torch.FloatTensor, h: torch.FloatTensor=None) -> tuple:\n",
        "        \"\"\"Pass the input sequence through all the RNN cells.\n",
        "        Returns the output and the final hidden state of each RNN layer\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            x: Input sequence.\n",
        "                Shape of [batch_size, seq_len, input_size].\n",
        "            h: Hidden state for each RNN layer.\n",
        "                Can be None, in which case an initial hidden state is created.\n",
        "                Shape of [batch_size, n_layers, hidden_size].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            y: Output embeddings for each token after the RNN layers.\n",
        "                Shape of [batch_size, seq_len, hidden_size].\n",
        "            h: Final hidden state.\n",
        "                Shape of [batch_size, n_layers, hidden_size].\n",
        "        \"\"\"\n",
        "        if h is None:\n",
        "          h = torch.zeros(x.shape[0], self.num_layers, self.hidden_size).to(x.device)\n",
        "\n",
        "        h = rearrange(h, 'b n h -> n b h')\n",
        "        h_next = torch.zeros(h.shape[0], h.shape[1], h.shape[2]).to(device)\n",
        "\n",
        "        y = x\n",
        "        for i, cell in enumerate(self.layers):\n",
        "          y, h_next[i] = cell(y, h[i])\n",
        "\n",
        "        h_next = rearrange(h_next, 'n b h -> b n h') \n",
        "        # y = torch.softmax(y, dim=2)\n",
        "        # y = self.linear(y)\n",
        "\n",
        "        return y, h_next\n",
        "\n"
      ],
      "metadata": {
        "id": "RiNKnwScM5Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_size = 5\n",
        "# hidden_size = 2\n",
        "# dropout = 0.005\n",
        "# batch_size = 3\n",
        "# num_layers = 2\n",
        "\n",
        "# cell = RNNCell(input_size, hidden_size, dropout)\n",
        "# x = torch.rand(batch_size, 4, input_size).to(device)\n",
        "# h = torch.rand(batch_size, hidden_size).to(device)\n",
        "# print(cell.forward(x, h))\n",
        "\n",
        "# rnn = RNN(input_size, hidden_size, num_layers, dropout)\n",
        "# x = torch.rand(batch_size, 4, input_size).to(device)\n",
        "# h = torch.rand(batch_size, num_layers ,hidden_size).to(device)\n",
        "# print(rnn.forward(x, h))"
      ],
      "metadata": {
        "id": "U_bXyyO0i2bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU\n",
        "Here you have to implement a GRU-RNN. This architecture is close to the Vanilla RNN but perform different operations. Look up the pytorch documentation to figure out the differences."
      ],
      "metadata": {
        "id": "I0ciaamtvK0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUCell(nn.Module):\n",
        "    \"\"\"A single GRU layer.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "        input_size: Size of each input token.\n",
        "        hidden_size: Size of each RNN hidden state.\n",
        "        dropout: Dropout rate.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size: int,\n",
        "            hidden_size: int,\n",
        "            dropout: float,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.Wir = nn.Linear(input_size, hidden_size).to(device)\n",
        "        self.Whr = nn.Linear(hidden_size, hidden_size).to(device)\n",
        "        self.Wiz = nn.Linear(input_size, hidden_size).to(device)\n",
        "        self.Whz = nn.Linear(hidden_size, hidden_size).to(device)\n",
        "        self.Win = nn.Linear(input_size, hidden_size).to(device)\n",
        "        self.Whn = nn.Linear(hidden_size, hidden_size).to(device)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.FloatTensor, h: torch.FloatTensor) -> tuple:\n",
        "        \"\"\"\n",
        "        Args\n",
        "        ----\n",
        "            x: Input sequence.\n",
        "                Shape of [batch_size, seq_len, input_size].\n",
        "            h: Initial hidden state.\n",
        "                Shape of [batch_size, hidden_size].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            y: Token embeddings.\n",
        "                Shape of [batch_size, seq_len, hidden_size].\n",
        "            h: Last hidden state.\n",
        "                Shape of [batch_size, hidden_size].\n",
        "        \"\"\"\n",
        "        x = rearrange(x, 'b s i -> s b i')\n",
        "        y = nn.Parameter(torch.empty((x.shape[0], x.shape[1], h.shape[1]))).to(x.device)\n",
        "        for i, seq in enumerate(x):\n",
        "          r_t = torch.sigmoid(self.Wir(seq) + self.Whr(h))\n",
        "          z_t = torch.sigmoid(self.Wiz(seq) + self.Whz(h))\n",
        "          n_t = torch.tanh(self.Win(seq) + r_t * self.Whn(h))\n",
        "          h = (1 - z_t) * n_t + z_t * h\n",
        "          h = self.dropout(h)\n",
        "          y[i] = h\n",
        "\n",
        "        y = rearrange(y, 's b i -> b s i')\n",
        "\n",
        "        return y, h\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    \"\"\"Implementation of a GRU based on https://pytorch.org/docs/stable/generated/torch.nn.GRU.html.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        input_size: Size of each input token.\n",
        "        hidden_size: Size of each RNN hidden state.\n",
        "        num_layers: Number of layers.\n",
        "        dropout: Dropout rate.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size: int,\n",
        "            hidden_size: int,\n",
        "            num_layers: int,\n",
        "            dropout: float,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Model\n",
        "        self.layers = nn.ModuleList([GRUCell(input_size, hidden_size, dropout)])\n",
        "        self.layers.extend(clones(GRUCell(hidden_size, hidden_size, dropout), num_layers-1))      \n",
        "\n",
        "    def forward(self, x: torch.FloatTensor, h: torch.FloatTensor=None) -> tuple:\n",
        "        \"\"\"\n",
        "        Args\n",
        "        ----\n",
        "            x: Input sequence\n",
        "                Shape of [batch_size, seq_len, input_size].\n",
        "            h: Initial hidden state for each layer.\n",
        "                If 'None', then an initial hidden state (a zero filled tensor)\n",
        "                is created.\n",
        "                Shape of [batch_size, n_layers, hidden_size].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            output:\n",
        "                Shape of [batch_size, seq_len, hidden_size].\n",
        "            h_n: Final hidden state.\n",
        "                Shape of [batch_size, n_layers, hidden size].\n",
        "        \"\"\"\n",
        "        if h is None:\n",
        "          h = torch.zeros(x.shape[0], self.num_layers, self.hidden_size).to(x.device)\n",
        "\n",
        "        h = rearrange(h, 'b n h -> n b h')\n",
        "        h_next = torch.zeros(h.shape[0], h.shape[1], h.shape[2]).to(device)\n",
        "        \n",
        "        y = x\n",
        "        for i, cell in enumerate(self.layers):\n",
        "          y, h_next[i] = cell(y, h[i]) \n",
        "\n",
        "        h_next = rearrange(h_next, 'n b h -> b n h')     \n",
        "        y = torch.softmax(y, dim=2)\n",
        "\n",
        "        return y, h_next\n"
      ],
      "metadata": {
        "id": "xdAMSZ7EMrMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_size = 5\n",
        "# hidden_size = 2\n",
        "# dropout = 0.005\n",
        "# batch_size = 3\n",
        "\n",
        "# cell = GRUCell(input_size, hidden_size, dropout)\n",
        "# x = torch.rand(batch_size, 4, input_size).to(device)\n",
        "# h = torch.rand(batch_size, hidden_size).to(device)\n",
        "# print(cell.forward(x, h))\n",
        "\n",
        "\n",
        "# rnn = GRU(input_size, hidden_size, num_layers, dropout)\n",
        "# x = torch.rand(batch_size, 4, input_size).to(device)\n",
        "# h = torch.rand(batch_size, num_layers ,hidden_size).to(device)\n",
        "# print(rnn.forward(x, h))"
      ],
      "metadata": {
        "id": "SJ0huBqWgAid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translation RNN\n",
        "\n",
        "This module instanciates a vanilla RNN or a GRU-RNN and performs the translation task. You have to:\n",
        "* Encode the source and target sequence\n",
        "* Pass the final hidden state of the encoder to the decoder (one for each layer)\n",
        "* Decode the hidden state into the target sequence\n",
        "\n",
        "We use teacher forcing for training, meaning that when the next token is predicted, that prediction is based on the previous true target tokens. "
      ],
      "metadata": {
        "id": "boIetZUy1f-5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD-6N17xhuLy"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.normalization import LayerNorm\n",
        "from torch.nn.modules.activation import LeakyReLU\n",
        "class TranslationRNN(nn.Module):\n",
        "    \"\"\"Basic RNN encoder and decoder for a translation task.\n",
        "    It can run as a vanilla RNN or a GRU-RNN.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        n_tokens_src: Number of tokens in the source vocabulary.\n",
        "        n_tokens_tgt: Number of tokens in the target vocabulary.\n",
        "        dim_embedding: Dimension size of the word embeddings (for both language).\n",
        "        dim_hidden: Dimension size of the hidden layers in the RNNs\n",
        "            (for both the encoder and the decoder).\n",
        "        n_layers: Number of layers in the RNNs.\n",
        "        dropout: Dropout rate.\n",
        "        src_pad_idx: Source padding index value.\n",
        "        tgt_pad_idx: Target padding index value.\n",
        "        model_type: Either 'RNN' or 'GRU', to select which model we want.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            n_tokens_src: int,\n",
        "            n_tokens_tgt: int,\n",
        "            dim_embedding: int,\n",
        "            dim_hidden: int,\n",
        "            n_layers: int,\n",
        "            dropout: float,\n",
        "            src_pad_idx: int,\n",
        "            tgt_pad_idx: int,\n",
        "            model_type: str,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "\n",
        "        self.embedding_en = nn.Embedding(n_tokens_src, dim_embedding, src_pad_idx)\n",
        "        self.embedding_fr = nn.Embedding(n_tokens_tgt, dim_embedding, tgt_pad_idx)\n",
        "\n",
        "        if model_type == 'RNN':\n",
        "          self.model_encoder = RNN(dim_embedding, dim_hidden, n_layers, dropout)\n",
        "          self.model_decoder = RNN(dim_embedding, dim_hidden, n_layers, dropout)\n",
        "\n",
        "        elif model_type == 'GRU':\n",
        "          self.model_encoder = GRU(dim_embedding, dim_hidden, n_layers, dropout)\n",
        "          self.model_decoder = GRU(dim_embedding, dim_hidden, n_layers, dropout)\n",
        "\n",
        "        self.fc = nn.Linear(dim_hidden * 2, dim_hidden)\n",
        "        self.layer_norm = nn.LayerNorm(dim_hidden)\n",
        "\n",
        "        # Architecture given in the Colab output\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.Linear(dim_hidden, dim_hidden),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(dim_hidden),\n",
        "            nn.Linear(dim_hidden, dim_hidden),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(dim_hidden),\n",
        "            nn.Linear(dim_hidden, dim_hidden),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(dim_hidden),\n",
        "            nn.Linear(dim_hidden, n_tokens_tgt)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        source: torch.LongTensor,\n",
        "        target: torch.LongTensor\n",
        "    ) -> torch.FloatTensor:\n",
        "        \"\"\"Predict the target tokens logites based on the source tokens.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            source: Batch of source sentences.\n",
        "                Shape of [batch_size, src_seq_len].\n",
        "            target: Batch of target sentences.\n",
        "                Shape of [batch_size, tgt_seq_len].\n",
        "        \n",
        "        Output\n",
        "        ------\n",
        "            y: Distributions over the next token for all tokens in each sentences.\n",
        "                Those need to be the logits only, do not apply a softmax because\n",
        "                it will be done in the loss computation for numerical stability.\n",
        "                See https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html for more informations.\n",
        "                Shape of [batch_size, tgt_seq_len, n_tokens_tgt].\n",
        "        \"\"\"\n",
        "        source = torch.fliplr(source)\n",
        "\n",
        "        embedded_source = self.embedding_en(source)\n",
        "        encoder_outputs, encoder_hidden = self.model_encoder(embedded_source)\n",
        "\n",
        "        encoder_hidden = self.layer_norm(encoder_hidden)\n",
        "\n",
        "\n",
        "        embedded_target = self.embedding_fr(target)\n",
        "        decoder_output, decoder_hidden = self.model_decoder(embedded_target, encoder_hidden)\n",
        "\n",
        "        outputs = self.sequential(decoder_output)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer model\n",
        "Here you have to code the Transformer architecture.\n",
        "It is divided in three parts:\n",
        "* Attention layers\n",
        "* Encoder and decoder layers\n",
        "* Main layers (gather the encoder and decoder layers)\n",
        "\n",
        "The [illustrated transformer](https://jalammar.github.io/illustrated-transformer/) blog can help you\n",
        "understanding how the architecture works.\n",
        "Once this is done, you can use [the annontated transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html) to have an idea of how to code this architecture.\n",
        "We encourage you to use `torch.einsum` and the `einops` library as much as you can. It will make your code simpler.\n",
        "\n",
        "---\n",
        "**Implementation order**\n",
        "\n",
        "To help you with the implementation, we advise you following this order:\n",
        "* Implement `TranslationTransformer` and use `nn.Transformer` instead of `Transformer`\n",
        "* Implement `Transformer` and use `nn.TransformerDecoder` and `nn.TransformerEnocder`\n",
        "* Implement the `TransformerDecoder` and `TransformerEncoder` and use `nn.MultiHeadAttention`\n",
        "* Implement `MultiHeadAttention`\n",
        "\n",
        "Do not forget to add `batch_first=True` when necessary in the `nn` modules."
      ],
      "metadata": {
        "id": "EZcGlRnZvOnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention layers\n",
        "We use a `MultiHeadAttention` module, that is able to perform self-attention aswell as cross-attention (depending on what you give as queries, keys and values).\n",
        "\n",
        "**Attention**\n",
        "\n",
        "\n",
        "It takes the multiheaded queries, keys and values as input.\n",
        "It computes the attention between the queries and the keys and return the attended values.\n",
        "\n",
        "The implementation of this function can greatly be improved with *einsums*.\n",
        "\n",
        "**MultiheadAttention**\n",
        "\n",
        "Computes the multihead queries, keys and values and feed them to the `attention` function.\n",
        "You also need to merge the key padding mask and the attention mask into one mask.\n",
        "\n",
        "The implementation of this module can greatly be improved with *einops.rearrange*."
      ],
      "metadata": {
        "id": "OFxV-6M3402p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "\n",
        "def attention(\n",
        "        q: torch.FloatTensor,\n",
        "        k: torch.FloatTensor,\n",
        "        v: torch.FloatTensor,\n",
        "        mask: torch.BoolTensor=None,\n",
        "        dropout: nn.Dropout=None,\n",
        "    ) -> tuple:\n",
        "    \"\"\"Computes multihead scaled dot-product attention from the\n",
        "    projected queries, keys and values.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        q: Batch of queries.\n",
        "            Shape of [batch_size, seq_len_1, n_heads, dim_model].\n",
        "        k: Batch of keys.\n",
        "            Shape of [batch_size, seq_len_2, n_heads, dim_model].\n",
        "        v: Batch of values.\n",
        "            Shape of [batch_size, seq_len_2, n_heads, dim_model].\n",
        "        mask: Prevent tokens to attend to some other tokens (for padding or autoregressive attention).\n",
        "            Attention is prevented where the mask is `True`.\n",
        "            Shape of [batch_size, n_heads, seq_len_1, seq_len_2],\n",
        "            or broadcastable to that shape.\n",
        "        dropout: Dropout layer to use.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        y: Multihead scaled dot-attention between the queries, keys and values.\n",
        "            Shape of [batch_size, seq_len_1, n_heads, dim_model].\n",
        "        attn: Computed attention mask.\n",
        "            Shape of [batch_size, n_heads, seq_len_1, seq_len_2].\n",
        "    \"\"\"\n",
        "    # Source: https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec\n",
        "    # Source: https://theaisummer.com/einsum-attention/\n",
        "\n",
        "    # Softmax(QK^T/sqrt(d)) and apply mask if defined\n",
        "    scaled_dot_prod  = torch.einsum(\"bshd, bsnd -> bshn\", q, k) / math.sqrt(q.shape[3])\n",
        "    if mask is not None: \n",
        "      scaled_dot_prod = scaled_dot_prod.masked_fill(mask==-math.inf, -math.inf)\n",
        "    attn = torch.softmax(scaled_dot_prod, dim=-1)\n",
        "\n",
        "    if dropout is not None:\n",
        "      attn = dropout(attn)\n",
        "\n",
        "    # Softmax(QK^T/sqrt(d))*V\n",
        "    y = torch.einsum('bhlt, bhtv -> bhlv', attn, v)\n",
        "\n",
        "    return y, attn\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "    \"\"\"Multihead attention module.\n",
        "    Can be used as a self-attention and cross-attention layer.\n",
        "    The queries, keys and values are projected into multiple heads\n",
        "    before computing the attention between those tensors.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        dim: Dimension of the input tokens.\n",
        "        n_heads: Number of heads. `dim` must be divisible by `n_heads`.\n",
        "        dropout: Dropout rate.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            dim: int,\n",
        "            n_heads: int,\n",
        "            dropout: float,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        assert dim % n_heads == 0\n",
        "\n",
        "        self.n_heads = n_heads\n",
        "        \n",
        "        self.q_linear = nn.Linear(dim, dim)\n",
        "        self.v_linear = nn.Linear(dim, dim)\n",
        "        self.k_linear = nn.Linear(dim, dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            q: torch.FloatTensor,\n",
        "            k: torch.FloatTensor,\n",
        "            v: torch.FloatTensor,\n",
        "            key_padding_mask: torch.BoolTensor = None,\n",
        "            attn_mask: torch.BoolTensor = None,\n",
        "        ) -> torch.FloatTensor:\n",
        "        \"\"\"Computes the scaled multi-head attention form the input queries,\n",
        "        keys and values.\n",
        "\n",
        "        Project those queries, keys and values before feeding them\n",
        "        to the `attention` function.\n",
        "\n",
        "        The masks are boolean masks. Tokens are prevented to attends to\n",
        "        positions where the mask is `True`.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            q: Batch of queries.\n",
        "                Shape of [batch_size, seq_len_1, dim_model].\n",
        "            k: Batch of keys.\n",
        "                Shape of [batch_size, seq_len_2, dim_model].\n",
        "            v: Batch of values.\n",
        "                Shape of [batch_size, seq_len_2, dim_model].\n",
        "            key_padding_mask: Prevent attending to padding tokens.\n",
        "                Shape of [batch_size, seq_len_2].\n",
        "            attn_mask: Prevent attending to subsequent tokens.\n",
        "                Shape of [seq_len_1, seq_len_2].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            y: Computed multihead attention.\n",
        "                Shape of [batch_size, seq_len_1, dim_model].\n",
        "        \"\"\"\n",
        "        # Source: https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec\n",
        "        # https://theaisummer.com/einsum-attention/\n",
        "        batch_size = q.size(0)\n",
        "\n",
        "        if key_padding_mask is None:\n",
        "          key_padding_mask = torch.ones((batch_size, k.size(1))).to(device)\n",
        "        \n",
        "        if attn_mask is None:\n",
        "          attn_mask = torch.ones((q.size(1), k.size(1))).to(device)\n",
        "        # print(f\"{key_padding_mask.shape} - {attn_mask.shape}\")\n",
        "\n",
        "        attn_mask = attn_mask.unsqueeze(0).repeat(batch_size, 1, 1)\n",
        "        key_padding_mask = key_padding_mask.unsqueeze(1)\n",
        "\n",
        "        mask = torch.add(key_padding_mask, attn_mask).unsqueeze(1)\n",
        "\n",
        "        # Perform linear operation and split into h heads\n",
        "        q = rearrange(self.q_linear(q), \"b s (h k) -> b h s k\", h=self.n_heads)\n",
        "        k = rearrange(self.k_linear(k), \"b s (h k) -> b h s k\", h=self.n_heads)\n",
        "        v = rearrange(self.v_linear(v), \"b s (h v) -> b h s v\", h=self.n_heads)\n",
        "        \n",
        "        # Calculate attention using function we will define next\n",
        "        y, attn = attention(q, k, v, mask, self.dropout)\n",
        "\n",
        "        # Concatenate heads and put through final linear layer\n",
        "        y = rearrange(y, 'b hnum s v -> b s (hnum v)')\n",
        "\n",
        "        y = self.out(y)\n",
        "    \n",
        "        return y\n"
      ],
      "metadata": {
        "id": "A0jOZxOwu_Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tgt = torch.Tensor([[1,2,0,0,0,0],\n",
        "                    [1,5,3,8,6,0]])\n",
        "\n",
        "def subsequent_mask(size):\n",
        "    \"Mask out subsequent positions.\"\n",
        "    return torch.triu(torch.ones(size, size) * float('-inf'), diagonal=1).cuda()\n",
        "\n",
        "\n",
        "def make_padding_mask(tgt, pad_idx):\n",
        "        \"Create a mask to hide padding and future words.\"\n",
        "        mask = torch.zeros_like(tgt, dtype = float).cuda()\n",
        "        mask[tgt == pad_idx] = float('-inf')\n",
        "        return mask\n",
        "\n",
        "\n",
        "padding = make_padding_mask(tgt, 0).unsqueeze(1)\n",
        "\n",
        "sub = subsequent_mask(tgt.size(1))\n",
        "sub = sub.unsqueeze(0).repeat(tgt.size(0), 1, 1)\n",
        "\n",
        "print(f\"Padding mask {padding.shape}\")\n",
        "print(padding)\n",
        "\n",
        "print(f\"\\nSub mask {sub.shape}\")\n",
        "print(sub)\n",
        "\n",
        "mask = torch.zeros_like(sub, dtype = float).cuda()\n",
        "\n",
        "mask = torch.add(padding, sub).unsqueeze(1)\n",
        "print(f\"\\nmask {mask.shape}\")\n",
        "print(mask)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B4wM_D5ZzsE",
        "outputId": "76fc6f3e-99b5-438a-eabe-9156ef2a2f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padding mask torch.Size([2, 1, 6])\n",
            "tensor([[[0., 0., -inf, -inf, -inf, -inf]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., -inf]]], device='cuda:0', dtype=torch.float64)\n",
            "\n",
            "Sub mask torch.Size([2, 6, 6])\n",
            "tensor([[[0., -inf, -inf, -inf, -inf, -inf],\n",
            "         [0., 0., -inf, -inf, -inf, -inf],\n",
            "         [0., 0., 0., -inf, -inf, -inf],\n",
            "         [0., 0., 0., 0., -inf, -inf],\n",
            "         [0., 0., 0., 0., 0., -inf],\n",
            "         [0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., -inf, -inf, -inf, -inf, -inf],\n",
            "         [0., 0., -inf, -inf, -inf, -inf],\n",
            "         [0., 0., 0., -inf, -inf, -inf],\n",
            "         [0., 0., 0., 0., -inf, -inf],\n",
            "         [0., 0., 0., 0., 0., -inf],\n",
            "         [0., 0., 0., 0., 0., 0.]]], device='cuda:0')\n",
            "\n",
            "mask torch.Size([2, 1, 6, 6])\n",
            "tensor([[[[0., -inf, -inf, -inf, -inf, -inf],\n",
            "          [0., 0., -inf, -inf, -inf, -inf],\n",
            "          [0., 0., -inf, -inf, -inf, -inf],\n",
            "          [0., 0., -inf, -inf, -inf, -inf],\n",
            "          [0., 0., -inf, -inf, -inf, -inf],\n",
            "          [0., 0., -inf, -inf, -inf, -inf]]],\n",
            "\n",
            "\n",
            "        [[[0., -inf, -inf, -inf, -inf, -inf],\n",
            "          [0., 0., -inf, -inf, -inf, -inf],\n",
            "          [0., 0., 0., -inf, -inf, -inf],\n",
            "          [0., 0., 0., 0., -inf, -inf],\n",
            "          [0., 0., 0., 0., 0., -inf],\n",
            "          [0., 0., 0., 0., 0., -inf]]]], device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder and decoder layers\n",
        "\n",
        "**TranformerEncoder**\n",
        "\n",
        "Apply self-attention layers onto the source tokens.\n",
        "It only needs the source key padding mask.\n",
        "\n",
        "\n",
        "**TranformerDecoder**\n",
        "\n",
        "Apply masked self-attention layers to the target tokens and cross-attention\n",
        "layers between the source and the target tokens.\n",
        "It needs the source and target key padding masks, and the target attention mask."
      ],
      "metadata": {
        "id": "nIpHjOtK47DH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoderLayer(nn.Module):\n",
        "    \"\"\"Single decoder layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        d_model: The dimension of decoders inputs/outputs.\n",
        "        dim_feedforward: Hidden dimension of the feedforward networks.\n",
        "        nheads: Number of heads for each multi-head attention.\n",
        "        dropout: Dropout rate.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            d_model: int,\n",
        "            d_ff: int,\n",
        "            nhead: int,\n",
        "            dropout: float\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.multihead_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            tgt: torch.FloatTensor,\n",
        "            src: torch.FloatTensor,\n",
        "            tgt_mask_attn: torch.BoolTensor,\n",
        "            src_key_padding_mask: torch.BoolTensor,\n",
        "            tgt_key_padding_mask: torch.BoolTensor,\n",
        "        ) -> torch.FloatTensor:\n",
        "        \"\"\"Decode the next target tokens based on the previous tokens.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            src: Batch of source sentences.\n",
        "                Shape of [batch_size, src_seq_len, dim_model].\n",
        "            tgt: Batch of target sentences.\n",
        "                Shape of [batch_size, tgt_seq_len, dim_model].\n",
        "            tgt_mask_attn: Mask to prevent attention to subsequent tokens.\n",
        "                Shape of [tgt_seq_len, tgt_seq_len].\n",
        "            src_key_padding_mask: Mask to prevent attention to padding in src sequence.\n",
        "                Shape of [batch_size, src_seq_len].\n",
        "            tgt_key_padding_mask: Mask to prevent attention to padding in tgt sequence.\n",
        "                Shape of [batch_size, tgt_seq_len].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            y:  Batch of sequence of embeddings representing the predicted target tokens\n",
        "                Shape of [batch_size, tgt_seq_len, dim_model].\n",
        "        \"\"\"\n",
        "        x = tgt\n",
        "        x = self.norm1(x + self.self_attn(x, x, x, attn_mask=tgt_mask_attn, key_padding_mask=tgt_key_padding_mask))\n",
        "        x = self.norm2(x + self.multihead_attn(x, src, src, key_padding_mask=src_key_padding_mask))\n",
        "        x = self.norm3(x + self._ff_block(x))\n",
        "\n",
        "        return x\n",
        "                       \n",
        "    def _ff_block(self, x):\n",
        "        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
        "        return self.dropout3(x)\n",
        "\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    \"\"\"Implementation of the transformer decoder stack.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        d_model: The dimension of decoders inputs/outputs.\n",
        "        dim_feedforward: Hidden dimension of the feedforward networks.\n",
        "        num_decoder_layers: Number of stacked decoders.\n",
        "        nheads: Number of heads for each multi-head attention.\n",
        "        dropout: Dropout rate.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            d_model: int,\n",
        "            d_ff: int,\n",
        "            num_decoder_layer:int ,\n",
        "            nhead: int,\n",
        "            dropout: float\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        decoder_layer = TransformerDecoderLayer(\n",
        "            d_model=d_model, \n",
        "            nhead=nhead, \n",
        "            d_ff=d_ff, \n",
        "            dropout=dropout\n",
        "        )\n",
        "        self.decoder_layers = clones(decoder_layer, num_decoder_layer)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            tgt: torch.FloatTensor,\n",
        "            memory: torch.FloatTensor,\n",
        "            tgt_mask_attn: torch.BoolTensor,\n",
        "            tgt_key_padding_mask: torch.BoolTensor,\n",
        "            memory_key_padding_mask: torch.BoolTensor,\n",
        "        ) -> torch.FloatTensor:\n",
        "        \"\"\"Decodes the source sequence by sequentially passing.\n",
        "        the encoded source sequence and the target sequence through the decoder stack.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            src: Batch of encoded source sentences.\n",
        "                Shape of [batch_size, src_seq_len, dim_model].\n",
        "            tgt: Batch of taget sentences.\n",
        "                Shape of [batch_size, tgt_seq_len, dim_model].\n",
        "            tgt_mask_attn: Mask to prevent attention to subsequent tokens.\n",
        "                Shape of [tgt_seq_len, tgt_seq_len].\n",
        "            src_key_padding_mask: Mask to prevent attention to padding in src sequence.\n",
        "                Shape of [batch_size, src_seq_len].\n",
        "            tgt_key_padding_mask: Mask to prevent attention to padding in tgt sequence.\n",
        "                Shape of [batch_size, tgt_seq_len].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            y:  Batch of sequence of embeddings representing the predicted target tokens\n",
        "                Shape of [batch_size, tgt_seq_len, dim_model].\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        output = tgt\n",
        "        for decoder_layer in self.decoder_layers:\n",
        "          output = decoder_layer(output, memory, \n",
        "                                 tgt_mask_attn=tgt_mask_attn, \n",
        "                                 tgt_key_padding_mask=tgt_key_padding_mask, \n",
        "                                 src_key_padding_mask=memory_key_padding_mask)\n",
        "        return output\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    \"\"\"Single encoder layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        d_model: The dimension of input tokens.\n",
        "        dim_feedforward: Hidden dimension of the feedforward networks.\n",
        "        nheads: Number of heads for each multi-head attention.\n",
        "        dropout: Dropout rate.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            d_model: int,\n",
        "            d_ff: int,\n",
        "            nhead: int,\n",
        "            dropout: float,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        src: torch.FloatTensor,\n",
        "        key_padding_mask: torch.BoolTensor\n",
        "        ) -> torch.FloatTensor:\n",
        "        \"\"\"Encodes the input. Does not attend to masked inputs.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            src: Batch of embedded source tokens.\n",
        "                Shape of [batch_size, src_seq_len, dim_model].\n",
        "            key_padding_mask: Mask preventing attention to padding tokens.\n",
        "                Shape of [batch_size, src_seq_len].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            y: Batch of encoded source tokens.\n",
        "                Shape of [batch_size, src_seq_len, dim_model].\n",
        "        \"\"\"\n",
        "        x = src\n",
        "        x = self.norm1(x + self.dropout1(self.self_attn(x, x, x, key_padding_mask=key_padding_mask)))\n",
        "        x = self.norm2(x + self._ff_block(x))\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def _ff_block(self, x):\n",
        "        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
        "        return self.dropout2(x)\n",
        "\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    \"\"\"Implementation of the transformer encoder stack.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        d_model: The dimension of encoders inputs.\n",
        "        dim_feedforward: Hidden dimension of the feedforward networks.\n",
        "        num_encoder_layers: Number of stacked encoders.\n",
        "        nheads: Number of heads for each multi-head attention.\n",
        "        dropout: Dropout rate.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            d_model: int,\n",
        "            dim_feedforward: int,\n",
        "            num_encoder_layers: int,\n",
        "            nheads: int,\n",
        "            dropout: float\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        encoder_layer = TransformerEncoderLayer(\n",
        "            d_model=d_model, \n",
        "            nhead=nheads, \n",
        "            d_ff=dim_feedforward, \n",
        "            dropout=dropout\n",
        "        )\n",
        "        self.encoder_layers = clones(encoder_layer, num_encoder_layers)\n",
        "\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            src: torch.FloatTensor,\n",
        "            key_padding_mask: torch.BoolTensor\n",
        "        ) -> torch.FloatTensor:\n",
        "        \"\"\"Encodes the source sequence by sequentially passing.\n",
        "        the source sequence through the encoder stack.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            src: Batch of embedded source sentences.\n",
        "                Shape of [batch_size, src_seq_len, dim_model].\n",
        "            key_padding_mask: Mask preventing attention to padding tokens.\n",
        "                Shape of [batch_size, src_seq_len].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            y: Batch of encoded source sequence.\n",
        "                Shape of [batch_size, src_seq_len, dim_model].\n",
        "        \"\"\"\n",
        "        output = src\n",
        "\n",
        "        for encoder in self.encoder_layers:\n",
        "            output = encoder(output, key_padding_mask=key_padding_mask)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "2d-ukpIOu_RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Encoding and Mask"
      ],
      "metadata": {
        "id": "L5lWcEqELH_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From: \n",
        "# - https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "# - https://nlp.seas.harvard.edu/2018/04/03/attention.html#batches-and-masking\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def subsequent_mask(size):\n",
        "    \"Mask out subsequent positions.\"\n",
        "    return torch.triu(torch.ones(size, size) * float('-inf'), diagonal=1).cuda()\n",
        "\n",
        "\n",
        "def make_padding_mask(tgt, pad_idx):\n",
        "        \"Create a mask to hide padding and future words.\"\n",
        "        mask = torch.zeros_like(tgt, dtype = float).cuda()\n",
        "        mask[tgt == pad_idx] = float('-inf')\n",
        "        return mask\n",
        "\n"
      ],
      "metadata": {
        "id": "mDqFcCGXFXhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main layers\n",
        "This section gather the `Transformer` and the `TranslationTransformer` modules.\n",
        "\n",
        "**Transformer**\n",
        "\n",
        "\n",
        "The classical transformer architecture.\n",
        "It takes the source and target tokens embeddings and\n",
        "do the forward pass through the encoder and decoder.\n",
        "\n",
        "**Translation Transformer**\n",
        "\n",
        "Compute the source and target tokens embeddings, and apply a final head to produce next token logits.\n",
        "The output must not be the softmax but just the logits, because we use the `nn.CrossEntropyLoss`.\n",
        "\n",
        "It also creates the *src_key_padding_mask*, the *tgt_key_padding_mask* and the *tgt_mask_attn*."
      ],
      "metadata": {
        "id": "Gd3kGoRO4_TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas._libs.tslibs.tzconversion import tz_convert_from_utc_single\n",
        "import torch.nn as nn\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"Implementation of a Transformer based on the paper: https://arxiv.org/pdf/1706.03762.pdf.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        d_model: The dimension of encoders/decoders inputs/ouputs.\n",
        "        nhead: Number of heads for each multi-head attention.\n",
        "        num_encoder_layers: Number of stacked encoders.\n",
        "        num_decoder_layers: Number of stacked encoders.\n",
        "        dim_feedforward: Hidden dimension of the feedforward networks.\n",
        "        dropout: Dropout rate.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            d_model: int =512,\n",
        "            nhead: int=8,\n",
        "            num_encoder_layers: int=6,\n",
        "            num_decoder_layers: int=6,\n",
        "            activation:str = \"relu\",\n",
        "            dim_feedforward: int=2048,\n",
        "            dropout: float=0.1,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.encoder = TransformerEncoder(\n",
        "            d_model, \n",
        "            dim_feedforward, \n",
        "            num_encoder_layers, \n",
        "            nhead, \n",
        "            dropout\n",
        "        )\n",
        "        \n",
        "        self.decoder = TransformerDecoder(\n",
        "            d_model, \n",
        "            dim_feedforward, \n",
        "            num_decoder_layers, \n",
        "            nhead, \n",
        "            dropout\n",
        "        )\n",
        "        \n",
        "\n",
        "        # self.transformer = nn.Transformer(\n",
        "        #     d_model=d_model,\n",
        "        #     nhead=nhead,\n",
        "        #     num_encoder_layers=num_encoder_layers,\n",
        "        #     num_decoder_layers=num_decoder_layers,\n",
        "        #     activation=activation,\n",
        "        #     dim_feedforward=dim_feedforward,\n",
        "        #     dropout=dropout,\n",
        "        #     batch_first=True\n",
        "        # )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            src: torch.FloatTensor,\n",
        "            tgt: torch.FloatTensor,\n",
        "            tgt_mask_attn: torch.BoolTensor,\n",
        "            src_key_padding_mask: torch.BoolTensor,\n",
        "            tgt_key_padding_mask: torch.BoolTensor\n",
        "        ) -> torch.FloatTensor:\n",
        "        \"\"\"Compute next token embeddings.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            src: Batch of source sequences.\n",
        "                Shape of [batch_size, src_seq_len, dim_model].\n",
        "            tgt: Batch of target sequences.\n",
        "                Shape of [batch_size, tgt_seq_len, dim_model].\n",
        "            tgt_mask_attn: Mask to prevent attention to subsequent tokens.\n",
        "                Shape of [tgt_seq_len, tgt_seq_len].\n",
        "            src_key_padding_mask: Mask to prevent attention to padding in src sequence.\n",
        "                Shape of [batch_size, src_seq_len].\n",
        "            tgt_key_padding_mask: Mask to prevent attention to padding in tgt sequence.\n",
        "                Shape of [batch_size, tgt_seq_len].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            y: Next token embeddings, given the previous target tokens and the source tokens.\n",
        "                Shape of [batch_size, tgt_seq_len, dim_model].\n",
        "        \"\"\"\n",
        "\n",
        "        # outputs = self.transformer(\n",
        "        #     src, \n",
        "        #     tgt, \n",
        "        #     tgt_mask = tgt_mask_attn,  \n",
        "        #     memory_mask = None, \n",
        "        #     src_key_padding_mask = src_key_padding_mask, \n",
        "        #     tgt_key_padding_mask = tgt_key_padding_mask, \n",
        "        #     memory_key_padding_mask = None\n",
        "        # )\n",
        "\n",
        "        outputs = self.encoder.forward(src, src_key_padding_mask)\n",
        "        outputs = self.decoder.forward(tgt, outputs, tgt_mask_attn, tgt_key_padding_mask, src_key_padding_mask)\n",
        "      \n",
        "        return outputs\n",
        "        \n",
        "\n",
        "\n",
        "class TranslationTransformer(nn.Module):\n",
        "    \"\"\"Basic Transformer encoder and decoder for a translation task.\n",
        "    Manage the masks creation, and the token embeddings.\n",
        "    Position embeddings can be learnt with a standard `nn.Embedding` layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        n_tokens_src: Number of tokens in the source vocabulary.\n",
        "        n_tokens_tgt: Number of tokens in the target vocabulary.\n",
        "        n_heads: Number of heads for each multi-head attention.\n",
        "        dim_embedding: Dimension size of the word embeddings (for both language).\n",
        "        dim_hidden: Dimension size of the feedforward layers\n",
        "            (for both the encoder and the decoder).\n",
        "        n_layers: Number of layers in the encoder and decoder.\n",
        "        dropout: Dropout rate.\n",
        "        src_pad_idx: Source padding index value.\n",
        "        tgt_pad_idx: Target padding index value.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            n_tokens_src: int,\n",
        "            n_tokens_tgt: int,\n",
        "            n_heads: int,\n",
        "            dim_embedding: int,\n",
        "            dim_hidden: int,\n",
        "            n_layers: int,\n",
        "            dropout: float,\n",
        "            src_pad_idx: int,\n",
        "            tgt_pad_idx: int,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_tokens_src = n_tokens_src\n",
        "        self.n_tokens_tgt = n_tokens_tgt\n",
        "        self.n_heads = n_heads\n",
        "        self.dim_embedding = dim_embedding\n",
        "        self.dim_hidden = dim_hidden\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.tgt_pad_idx = tgt_pad_idx\n",
        "\n",
        "        self.pos_encoder = PositionalEncoding(dim_embedding, dropout)\n",
        "\n",
        "        self.embedding_en = nn.Embedding(n_tokens_src, dim_embedding)\n",
        "        self.embedding_fr = nn.Embedding(n_tokens_tgt, dim_embedding)\n",
        "\n",
        "        self.pos_encoder = PositionalEncoding(dim_embedding, dropout)\n",
        "\n",
        "        self.my_transformer = Transformer(\n",
        "            d_model=dim_embedding, \n",
        "            nhead=n_heads, \n",
        "            num_encoder_layers=n_layers, \n",
        "            num_decoder_layers=n_layers, \n",
        "            dim_feedforward=dim_hidden, \n",
        "            dropout=dropout)\n",
        "        \n",
        "        # self.transformer = nn.Transformer(\n",
        "        #     d_model = dim_embedding, \n",
        "        #     nhead = n_heads, \n",
        "        #     num_encoder_layers = n_layers, \n",
        "        #     num_decoder_layers = n_layers, \n",
        "        #     dim_feedforward = dim_hidden, \n",
        "        #     dropout = dropout, \n",
        "        #     batch_first = True\n",
        "        # )\n",
        "        \n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.Linear(dim_embedding, dim_embedding),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(dim_embedding),\n",
        "            nn.Linear(dim_embedding, dim_embedding),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(dim_embedding),\n",
        "            nn.Linear(dim_embedding, dim_embedding),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(dim_embedding),\n",
        "            nn.Linear(dim_embedding, n_tokens_tgt)\n",
        "        )\n",
        "        self.linear = nn.Linear(dim_embedding, n_tokens_tgt)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            source: torch.LongTensor,\n",
        "            target: torch.LongTensor\n",
        "        ) -> torch.FloatTensor:\n",
        "        \"\"\"Predict the target tokens logites based on the source tokens.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "            source: Batch of source sentences.\n",
        "                Shape of [batch_size, seq_len_src].\n",
        "            target: Batch of target sentences.\n",
        "                Shape of [batch_size, seq_len_tgt].\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "            y: Distributions over the next token for all tokens in each sentences.\n",
        "                Those need to be the logits only, do not apply a softmax because\n",
        "                it will be done in the loss computation for numerical stability.\n",
        "                See https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html for more informations.\n",
        "                Shape of [batch_size, seq_len_tgt, n_tokens_tgt].\n",
        "        \"\"\"\n",
        "        # Create the masks\n",
        "        tgt_mask = subsequent_mask(target.size(1))\n",
        "\n",
        "        # Create the padding masks\n",
        "        src_key_padding_mask = make_padding_mask(source, self.src_pad_idx)\n",
        "        tgt_key_padding_mask = make_padding_mask(target, self.tgt_pad_idx)\n",
        "\n",
        "        # Embeddings\n",
        "        embedded_en = self.pos_encoder(self.embedding_en(source)*math.sqrt(self.dim_embedding))\n",
        "        embedded_fr = self.pos_encoder(self.embedding_fr(target)*math.sqrt(self.dim_embedding))\n",
        "\n",
        "        outputs = self.my_transformer(\n",
        "            embedded_en, \n",
        "            embedded_fr, \n",
        "            tgt_mask_attn = tgt_mask, \n",
        "            src_key_padding_mask = src_key_padding_mask, \n",
        "            tgt_key_padding_mask = tgt_key_padding_mask, \n",
        "        )\n",
        "        \n",
        "        return self.sequential(outputs)\n"
      ],
      "metadata": {
        "id": "AGYVF34mvRNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Greedy search\n",
        "\n",
        "Here you have to implement a geedy search to generate a target translation from a trained model and an input source string.\n",
        "The next token will simply be the most probable one."
      ],
      "metadata": {
        "id": "ql6jv2lAK-nF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#greedy search is basically beam search but only with a beam width of 1.\n",
        "def indices_terminated(\n",
        "        target: torch.FloatTensor,\n",
        "        eos_token: int\n",
        "    ) -> tuple:\n",
        "    \"\"\"Split the target sentences between the terminated and the non-terminated\n",
        "    sentence. Return the indices of those two groups.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        target: The sentences.\n",
        "            Shape of [batch_size, n_tokens].\n",
        "        eos_token: Value of the End-of-Sentence token.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        terminated: Indices of the terminated sentences (who's got the eos_token).\n",
        "            Shape of [n_terminated, ].\n",
        "        non-terminated: Indices of the unfinished sentences.\n",
        "            Shape of [batch_size-n_terminated, ].\n",
        "    \"\"\"\n",
        "    terminated = [i for i, t in enumerate(target) if eos_token in t]\n",
        "    non_terminated = [i for i, t in enumerate(target) if eos_token not in t]\n",
        "    return torch.LongTensor(terminated), torch.LongTensor(non_terminated)\n",
        "\n",
        "\n",
        "def append_beams(\n",
        "        target: torch.FloatTensor,\n",
        "        beams: torch.FloatTensor\n",
        "    ) -> torch.FloatTensor:\n",
        "    \"\"\"Add the beam tokens to the current sentences.\n",
        "    Duplicate the sentences so one token is added per beam per batch.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        target: Batch of unfinished sentences.\n",
        "            Shape of [batch_size, n_tokens].\n",
        "        beams: Batch of beams for each sentences.\n",
        "            Shape of [batch_size, n_beams].\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        target: Batch of sentences with one beam per sentence.\n",
        "            Shape of [batch_size * n_beams, n_tokens+1].\n",
        "    \"\"\"\n",
        "    batch_size, n_beams = beams.shape\n",
        "    n_tokens = target.shape[1]\n",
        "\n",
        "    target = einops.repeat(target, 'b t -> b c t', c=n_beams)  # [batch_size, n_beams, n_tokens]\n",
        "    beams = beams.unsqueeze(dim=2)  # [batch_size, n_beams, 1]\n",
        "\n",
        "    target = torch.cat((target, beams), dim=2)  # [batch_size, n_beams, n_tokens+1]\n",
        "    target = target.view(batch_size*n_beams, n_tokens+1)  # [batch_size * n_beams, n_tokens+1]\n",
        "    return target\n",
        "\n",
        "\n",
        "def greedy_search(\n",
        "        model: nn.Module,\n",
        "        source: str,\n",
        "        src_vocab: Vocab,\n",
        "        tgt_vocab: Vocab,\n",
        "        src_tokenizer,\n",
        "        device: str,\n",
        "        max_sentence_length: int,\n",
        "    ) -> str:\n",
        "    \"\"\"Do a beam search to produce probable translations.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        model: The translation model. Assumes it produces logits score (before softmax).\n",
        "        source: The sentence to translate.\n",
        "        src_vocab: The source vocabulary.\n",
        "        tgt_vocab: The target vocabulary.\n",
        "        device: Device to which we make the inference.\n",
        "        max_target: Maximum number of target sentences we keep at the end of each stage.\n",
        "        max_sentence_length: Maximum number of tokens for the translated sentence.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        sentence: The translated source sentence.\n",
        "    \"\"\"\n",
        "    \n",
        "    src_tokens = ['<bos>'] + src_tokenizer(source) + ['<eos>']\n",
        "    src_tokens = src_vocab(src_tokens)\n",
        "\n",
        "    tgt_tokens = ['<bos>']\n",
        "    tgt_tokens = tgt_vocab(tgt_tokens)\n",
        "\n",
        "    # To tensor and add unitary batch dimension\n",
        "    src_tokens = torch.LongTensor(src_tokens).to(device)\n",
        "    tgt_tokens = torch.LongTensor(tgt_tokens).unsqueeze(dim=0).to(device)\n",
        "    target_probs = torch.FloatTensor([1]).to(device)\n",
        "    model.to(device)\n",
        "\n",
        "    EOS_IDX = tgt_vocab['<eos>']\n",
        "    with torch.no_grad():\n",
        "        while tgt_tokens.shape[1] < max_sentence_length:\n",
        "            batch_size, n_tokens = tgt_tokens.shape\n",
        "\n",
        "            # Get next beams\n",
        "            src = einops.repeat(src_tokens, 't -> b t', b=tgt_tokens.shape[0])\n",
        "            predicted = model.forward(src, tgt_tokens)\n",
        "            predicted = torch.softmax(predicted, dim=-1)\n",
        "            probs, predicted = predicted[:, -1].topk(k=1, dim=-1)\n",
        "\n",
        "            # Separe between terminated sentences and the others\n",
        "            idx_terminated, idx_not_terminated = indices_terminated(tgt_tokens, EOS_IDX)\n",
        "            idx_terminated, idx_not_terminated = idx_terminated.to(device), idx_not_terminated.to(device)\n",
        "\n",
        "            tgt_terminated = torch.index_select(tgt_tokens, dim=0, index=idx_terminated)\n",
        "            tgt_probs_terminated = torch.index_select(target_probs, dim=0, index=idx_terminated)\n",
        "\n",
        "            filter_t = lambda t: torch.index_select(t, dim=0, index=idx_not_terminated)\n",
        "            tgt_others = filter_t(tgt_tokens)\n",
        "            tgt_probs_others = filter_t(target_probs)\n",
        "            predicted = filter_t(predicted)\n",
        "            probs = filter_t(probs)\n",
        "\n",
        "            # Add the top tokens to the previous target sentences\n",
        "            tgt_others = append_beams(tgt_others, predicted)\n",
        "\n",
        "            # Add padding to terminated target\n",
        "            padd = torch.zeros((len(tgt_terminated), 1), dtype=torch.long, device=device)\n",
        "            tgt_terminated = torch.cat(\n",
        "                (tgt_terminated, padd),\n",
        "                dim=1\n",
        "            )\n",
        "\n",
        "            # Update each target sentence probabilities\n",
        "            tgt_probs_others = torch.repeat_interleave(tgt_probs_others, 1)\n",
        "            tgt_probs_others *= probs.flatten()\n",
        "            tgt_probs_terminated *= 0.999  # Penalize short sequences overtime\n",
        "\n",
        "            # Group up the terminated and the others\n",
        "            target_probs = torch.cat(\n",
        "                (tgt_probs_others, tgt_probs_terminated),\n",
        "                dim=0\n",
        "            )\n",
        "            tgt_tokens = torch.cat(\n",
        "                (tgt_others, tgt_terminated),\n",
        "                dim=0\n",
        "            )\n",
        "\n",
        "            # Keep only the top `max_target` target sentences\n",
        "            target_probs, indices = target_probs.topk(k=1, dim=0)\n",
        "\n",
        "            tgt_tokens = torch.index_select(tgt_tokens, dim=0, index=indices)\n",
        "\n",
        "    sentences = []\n",
        "    for tgt_sentence in tgt_tokens:\n",
        "        tgt_sentence = list(tgt_sentence)[1:]  # Remove <bos> token\n",
        "        tgt_sentence = list(takewhile(lambda t: t != EOS_IDX, tgt_sentence))\n",
        "        tgt_sentence = ' '.join(tgt_vocab.lookup_tokens(tgt_sentence))\n",
        "        sentences.append(tgt_sentence)\n",
        "\n",
        "    sentences = [beautify(s) for s in sentences]\n",
        "\n",
        "    # Join the sentences with their likelihood\n",
        "    sentences = [(s, p.item()) for s, p in zip(sentences, target_probs)]\n",
        "    # Sort the sentences by their likelihood\n",
        "    sentences = [(s, p) for s, p in sorted(sentences, key=lambda k: k[1], reverse=True)]\n",
        "\n",
        "    return sentences\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-KMp7piKK905"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Beam search\n",
        "Beam search is a smarter way of producing a sequence of tokens from\n",
        "an autoregressive model than just using a greedy search.\n",
        "\n",
        "The greedy search always choose the most probable token as the unique\n",
        "and only next target token, and repeat this processus until the *\\<eos\\>* token is predicted.\n",
        "\n",
        "Instead, the beam search selects the k-most probable tokens at each step.\n",
        "From those k tokens, the current sequence is duplicated k times and the k tokens are appended to the k sequences to produce new k sequences.\n",
        "\n",
        "*You don't have to understand this code, but understanding this code once the TP is over could improve your torch tensors skills.*\n",
        "\n",
        "---\n",
        "\n",
        "**More explanations**\n",
        "\n",
        "Since it is done at each step, the number of sequences grows exponentially (k sequences after the first step, k² sequences after the second...).\n",
        "In order to keep the number of sequences low, we remove sequences except the top-s most likely sequences.\n",
        "To do that, we keep track of the likelihood of each sequence.\n",
        "\n",
        "Formally, we define $s = [s_1, ..., s_{N_s}]$ as the source sequence made of $N_s$ tokens.\n",
        "We also define $t^i = [t_1, ..., t_i]$ as the target sequence at the beginning of the step $i$.\n",
        "\n",
        "The output of the model parameterized by $\\theta$ is:\n",
        "\n",
        "$$\n",
        "T_{i+1} = p(t_{i+1} | s, t^i ; \\theta )\n",
        "$$\n",
        "\n",
        "Where $T_{i+1}$ is the distribution of the next token $t_{i+1}$.\n",
        "\n",
        "Then, we define the likelihood of a target sentence $t = [t_1, ..., t_{N_t}]$ as:\n",
        "\n",
        "$$\n",
        "L(t) = \\prod_{i=1}^{N_t - 1} p(t_{i+1} | s, t_{i}; \\theta )\n",
        "$$\n",
        "\n",
        "Pseudocode of the beam search:\n",
        "```\n",
        "source: [N_s source tokens]  # Shape of [total_source_tokens]\n",
        "target: [1, <bos> token]  # Shape of [n_sentences, current_target_tokens]\n",
        "target_prob: [1]  # Shape of [n_sentences]\n",
        "# We use `n_sentences` as the batch_size dimension\n",
        "\n",
        "while current_target_tokens <= max_target_length:\n",
        "    source = repeat(source, n_sentences)  # Shape of [n_sentences, total_source_tokens]\n",
        "    predicted = model(source, target)[:, -1]  # Predict the next token distributions of all the n_sentences\n",
        "    tokens_idx, tokens_prob = topk(predicted, k)\n",
        "\n",
        "    # Append the `n_sentences * k` tokens to the `n_sentences` sentences\n",
        "    target = repeat(target, k)  # Shape of [n_sentences * k, current_target_tokens]\n",
        "    target = append_tokens(target, tokens_idx)  # Shape of [n_sentences * k, current_target_tokens + 1]\n",
        "\n",
        "    # Update the sentences probabilities\n",
        "    target_prob = repeat(target_prob, k)  # Shape of [n_sentences * k]\n",
        "    target_prob *= tokens_prob\n",
        "\n",
        "    if n_sentences * k >= max_sentences:\n",
        "        target, target_prob = topk_prob(target, target_prob, k=max_sentences)\n",
        "    else:\n",
        "        n_sentences *= k\n",
        "\n",
        "    current_target_tokens += 1\n",
        "```"
      ],
      "metadata": {
        "id": "LgGFG-uXue6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def beautify(sentence: str) -> str:\n",
        "    \"\"\"Removes useless spaces.\n",
        "    \"\"\"\n",
        "    punc = {'.', ',', ';'}\n",
        "    for p in punc:\n",
        "        sentence = sentence.replace(f' {p}', p)\n",
        "    \n",
        "    links = {'-', \"'\"}\n",
        "    for l in links:\n",
        "        sentence = sentence.replace(f'{l} ', l)\n",
        "        sentence = sentence.replace(f' {l}', l)\n",
        "    \n",
        "    return sentence"
      ],
      "metadata": {
        "id": "V-GomgGTY2sV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9Q7qcvH2Chp"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def beam_search(\n",
        "        model: nn.Module,\n",
        "        source: str,\n",
        "        src_vocab: Vocab,\n",
        "        tgt_vocab: Vocab,\n",
        "        src_tokenizer,\n",
        "        device: str,\n",
        "        beam_width: int,\n",
        "        max_target: int,\n",
        "        max_sentence_length: int,\n",
        "    ) -> list:\n",
        "    \"\"\"Do a beam search to produce probable translations.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        model: The translation model. Assumes it produces linear score (before softmax).\n",
        "        source: The sentence to translate.\n",
        "        src_vocab: The source vocabulary.\n",
        "        tgt_vocab: The target vocabulary.\n",
        "        device: Device to which we make the inference.\n",
        "        beam_width: Number of top-k tokens we keep at each stage.\n",
        "        max_target: Maximum number of target sentences we keep at the end of each stage.\n",
        "        max_sentence_length: Maximum number of tokens for the translated sentence.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        sentences: List of sentences orderer by their likelihood.\n",
        "    \"\"\"\n",
        "    src_tokens = ['<bos>'] + src_tokenizer(source) + ['<eos>']\n",
        "    src_tokens = src_vocab(src_tokens)\n",
        "\n",
        "    tgt_tokens = ['<bos>']\n",
        "    tgt_tokens = tgt_vocab(tgt_tokens)\n",
        "\n",
        "    # To tensor and add unitary batch dimension\n",
        "    src_tokens = torch.LongTensor(src_tokens).to(device)\n",
        "    tgt_tokens = torch.LongTensor(tgt_tokens).unsqueeze(dim=0).to(device)\n",
        "    target_probs = torch.FloatTensor([1]).to(device)\n",
        "    model.to(device)\n",
        "\n",
        "    EOS_IDX = tgt_vocab['<eos>']\n",
        "    with torch.no_grad():\n",
        "        while tgt_tokens.shape[1] < max_sentence_length:\n",
        "            batch_size, n_tokens = tgt_tokens.shape\n",
        "\n",
        "            # Get next beams\n",
        "            src = einops.repeat(src_tokens, 't -> b t', b=tgt_tokens.shape[0])\n",
        "            predicted = model.forward(src, tgt_tokens)\n",
        "            predicted = torch.softmax(predicted, dim=-1)\n",
        "            probs, predicted = predicted[:, -1].topk(k=beam_width, dim=-1)\n",
        "\n",
        "            # Separe between terminated sentences and the others\n",
        "            idx_terminated, idx_not_terminated = indices_terminated(tgt_tokens, EOS_IDX)\n",
        "            idx_terminated, idx_not_terminated = idx_terminated.to(device), idx_not_terminated.to(device)\n",
        "\n",
        "            tgt_terminated = torch.index_select(tgt_tokens, dim=0, index=idx_terminated)\n",
        "            tgt_probs_terminated = torch.index_select(target_probs, dim=0, index=idx_terminated)\n",
        "\n",
        "            filter_t = lambda t: torch.index_select(t, dim=0, index=idx_not_terminated)\n",
        "            tgt_others = filter_t(tgt_tokens)\n",
        "            tgt_probs_others = filter_t(target_probs)\n",
        "            predicted = filter_t(predicted)\n",
        "            probs = filter_t(probs)\n",
        "\n",
        "            # Add the top tokens to the previous target sentences\n",
        "            tgt_others = append_beams(tgt_others, predicted)\n",
        "\n",
        "            # Add padding to terminated target\n",
        "            padd = torch.zeros((len(tgt_terminated), 1), dtype=torch.long, device=device)\n",
        "            tgt_terminated = torch.cat(\n",
        "                (tgt_terminated, padd),\n",
        "                dim=1\n",
        "            )\n",
        "\n",
        "            # Update each target sentence probabilities\n",
        "            tgt_probs_others = torch.repeat_interleave(tgt_probs_others, beam_width)\n",
        "            tgt_probs_others *= probs.flatten()\n",
        "            tgt_probs_terminated *= 0.999  # Penalize short sequences overtime\n",
        "\n",
        "            # Group up the terminated and the others\n",
        "            target_probs = torch.cat(\n",
        "                (tgt_probs_others, tgt_probs_terminated),\n",
        "                dim=0\n",
        "            )\n",
        "            tgt_tokens = torch.cat(\n",
        "                (tgt_others, tgt_terminated),\n",
        "                dim=0\n",
        "            )\n",
        "\n",
        "            # Keep only the top `max_target` target sentences\n",
        "            if target_probs.shape[0] <= max_target:\n",
        "                continue\n",
        "\n",
        "            target_probs, indices = target_probs.topk(k=max_target, dim=0)\n",
        "            tgt_tokens = torch.index_select(tgt_tokens, dim=0, index=indices)\n",
        "\n",
        "    sentences = []\n",
        "    for tgt_sentence in tgt_tokens:\n",
        "        tgt_sentence = list(tgt_sentence)[1:]  # Remove <bos> token\n",
        "        tgt_sentence = list(takewhile(lambda t: t != EOS_IDX, tgt_sentence))\n",
        "        tgt_sentence = ' '.join(tgt_vocab.lookup_tokens(tgt_sentence))\n",
        "        sentences.append(tgt_sentence)\n",
        "\n",
        "    sentences = [beautify(s) for s in sentences]\n",
        "\n",
        "    # Join the sentences with their likelihood\n",
        "    sentences = [(s, p.item()) for s, p in zip(sentences, target_probs)]\n",
        "    # Sort the sentences by their likelihood\n",
        "    sentences = [(s, p) for s, p in sorted(sentences, key=lambda k: k[1], reverse=True)]\n",
        "\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVr2FuDcZxC6"
      },
      "source": [
        "# Training loop\n",
        "This is a basic training loop code. It takes a big configuration dictionnary to avoid never ending arguments in the functions.\n",
        "We use [Weights and Biases](https://wandb.ai/) to log the trainings.\n",
        "It logs every training informations and model performances in the cloud.\n",
        "You have to create an account to use it. Every accounts are free for individuals or research teams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2I1C8pRXN8j"
      },
      "outputs": [],
      "source": [
        "def print_logs(dataset_type: str, logs: dict):\n",
        "    \"\"\"Print the logs.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        dataset_type: Either \"Train\", \"Eval\", \"Test\" type.\n",
        "        logs: Containing the metric's name and value.\n",
        "    \"\"\"\n",
        "    desc = [\n",
        "        f'{name}: {value:.2f}'\n",
        "        for name, value in logs.items()\n",
        "    ]\n",
        "    desc = '\\t'.join(desc)\n",
        "    desc = f'{dataset_type} -\\t' + desc\n",
        "    desc = desc.expandtabs(5)\n",
        "    print(desc)\n",
        "\n",
        "\n",
        "def topk_accuracy(\n",
        "        real_tokens: torch.FloatTensor,\n",
        "        probs_tokens: torch.FloatTensor,\n",
        "        k: int,\n",
        "        tgt_pad_idx: int,\n",
        "    ) -> torch.FloatTensor:\n",
        "    \"\"\"Compute the top-k accuracy.\n",
        "    We ignore the PAD tokens.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        real_tokens: Real tokens of the target sentence.\n",
        "            Shape of [batch_size * n_tokens].\n",
        "        probs_tokens: Tokens probability predicted by the model.\n",
        "            Shape of [batch_size * n_tokens, n_target_vocabulary].\n",
        "        k: Top-k accuracy threshold.\n",
        "        src_pad_idx: Source padding index value.\n",
        "    \n",
        "    Output\n",
        "    ------\n",
        "        acc: Scalar top-k accuracy value.\n",
        "    \"\"\"\n",
        "    total = (real_tokens != tgt_pad_idx).sum()\n",
        "\n",
        "    _, pred_tokens = probs_tokens.topk(k=k, dim=-1)  # [batch_size * n_tokens, k]\n",
        "    real_tokens = einops.repeat(real_tokens, 'b -> b k', k=k)  # [batch_size * n_tokens, k]\n",
        "\n",
        "    good = (pred_tokens == real_tokens) & (real_tokens != tgt_pad_idx)\n",
        "    acc = good.sum() / total\n",
        "    return acc\n",
        "\n",
        "\n",
        "def loss_batch(\n",
        "        model: nn.Module,\n",
        "        source: torch.LongTensor,\n",
        "        target: torch.LongTensor,\n",
        "        config: dict,\n",
        "    )-> dict:\n",
        "    \"\"\"Compute the metrics associated with this batch.\n",
        "    The metrics are:\n",
        "        - loss\n",
        "        - top-1 accuracy\n",
        "        - top-5 accuracy\n",
        "        - top-10 accuracy\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        model: The model to train.\n",
        "        source: Batch of source tokens.\n",
        "            Shape of [batch_size, n_src_tokens].\n",
        "        target: Batch of target tokens.\n",
        "            Shape of [batch_size, n_tgt_tokens].\n",
        "        config: Additional parameters.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        metrics: Dictionnary containing evaluated metrics on this batch.\n",
        "    \"\"\"\n",
        "    device = config['device']\n",
        "    loss_fn = config['loss'].to(device)\n",
        "    metrics = dict()\n",
        "\n",
        "    source, target = source.to(device), target.to(device)\n",
        "    target_in, target_out = target[:, :-1], target[:, 1:]\n",
        "\n",
        "    # Loss\n",
        "    pred = model(source, target_in)  # [batch_size, n_tgt_tokens-1, n_vocab]\n",
        "    pred = pred.view(-1, pred.shape[2])  # [batch_size * (n_tgt_tokens - 1), n_vocab]\n",
        "    target_out = target_out.flatten()  # [batch_size * (n_tgt_tokens - 1),]\n",
        "    metrics['loss'] = loss_fn(pred, target_out)\n",
        "\n",
        "    # Accuracy - we ignore the padding predictions\n",
        "    for k in [1, 5, 10]:\n",
        "        metrics[f'top-{k}'] = topk_accuracy(target_out, pred, k, config['tgt_pad_idx'])\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def eval_model(model: nn.Module, dataloader: DataLoader, config: dict) -> dict:\n",
        "    \"\"\"Evaluate the model on the given dataloader.\n",
        "    \"\"\"\n",
        "    device = config['device']\n",
        "    logs = defaultdict(list)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for source, target in dataloader:\n",
        "            metrics = loss_batch(model, source, target, config)\n",
        "            for name, value in metrics.items():\n",
        "                logs[name].append(value.cpu().item())\n",
        "\n",
        "    for name, values in logs.items():\n",
        "        logs[name] = np.mean(values)\n",
        "    return logs\n",
        "\n",
        "\n",
        "def train_model(model: nn.Module, config: dict):\n",
        "    \"\"\"Train the model in a teacher forcing manner.\n",
        "    \"\"\"\n",
        "    train_loader, val_loader = config['train_loader'], config['val_loader']\n",
        "    train_dataset, val_dataset = train_loader.dataset.dataset, val_loader.dataset.dataset\n",
        "    optimizer = config['optimizer']\n",
        "    clip = config['clip']\n",
        "    device = config['device']\n",
        "\n",
        "    columns = ['epoch']\n",
        "    for mode in ['train', 'validation']:\n",
        "        columns += [\n",
        "            f'{mode} - {colname}'\n",
        "            for colname in ['source', 'target', 'predicted', 'likelihood']\n",
        "        ]\n",
        "    log_table = wandb.Table(columns=columns)\n",
        "\n",
        "\n",
        "    print(f'Starting training for {config[\"epochs\"]} epochs, using {device}.')\n",
        "    for e in range(config['epochs']):\n",
        "        print(f'\\nEpoch {e+1}')\n",
        "\n",
        "        model.to(device)\n",
        "        model.train()\n",
        "        logs = defaultdict(list)\n",
        "\n",
        "        for batch_id, (source, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            metrics = loss_batch(model, source, target, config)\n",
        "            loss = metrics['loss']\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            optimizer.step()\n",
        "        \n",
        "            for name, value in metrics.items():\n",
        "                logs[name].append(value.cpu().item())  # Don't forget the '.item' to free the cuda memory\n",
        "            \n",
        "            if batch_id % config['log_every'] == 0:\n",
        "                for name, value in logs.items():\n",
        "                    logs[name] = np.mean(value)\n",
        "\n",
        "                train_logs = {\n",
        "                    f'Train - {m}': v\n",
        "                    for m, v in logs.items()\n",
        "                }\n",
        "                wandb.log(train_logs)\n",
        "                logs = defaultdict(list)\n",
        "        \n",
        "        # Logs\n",
        "        if len(logs) != 0:\n",
        "            for name, value in logs.items():\n",
        "                logs[name] = np.mean(value)\n",
        "            train_logs = {\n",
        "                f'Train - {m}': v\n",
        "                for m, v in logs.items()\n",
        "            }\n",
        "        else:\n",
        "            logs = {\n",
        "                m.split(' - ')[1]: v\n",
        "                for m, v in train_logs.items()\n",
        "            }\n",
        "\n",
        "        print_logs('Train', logs)\n",
        "\n",
        "        logs = eval_model(model, val_loader, config)\n",
        "        print_logs('Eval', logs)\n",
        "        val_logs = {\n",
        "            f'Validation - {m}': v\n",
        "            for m, v in logs.items()\n",
        "        }\n",
        "\n",
        "        val_source, val_target = val_dataset[ torch.randint(len(val_dataset), (1,)) ]\n",
        "        val_pred, val_prob = beam_search(\n",
        "            model,\n",
        "            val_source,\n",
        "            config['src_vocab'],\n",
        "            config['tgt_vocab'],\n",
        "            config['src_tokenizer'],\n",
        "            device,  # It can take a lot of VRAM\n",
        "            beam_width=10,\n",
        "            max_target=100,\n",
        "            max_sentence_length=config['max_sequence_length'],\n",
        "        )[0]\n",
        "        print(val_source)\n",
        "        print(val_pred)\n",
        "\n",
        "        logs = {**train_logs, **val_logs}  # Merge dictionnaries\n",
        "        wandb.log(logs)  # Upload to the WandB cloud\n",
        "\n",
        "        # Table logs\n",
        "        train_source, train_target = train_dataset[ torch.randint(len(train_dataset), (1,)) ]\n",
        "        train_pred, train_prob = beam_search(\n",
        "            model,\n",
        "            train_source,\n",
        "            config['src_vocab'],\n",
        "            config['tgt_vocab'],\n",
        "            config['src_tokenizer'],\n",
        "            device,  # It can take a lot of VRAM\n",
        "            beam_width=10,\n",
        "            max_target=100,\n",
        "            max_sentence_length=config['max_sequence_length'],\n",
        "        )[0]\n",
        "\n",
        "        data = [\n",
        "            e + 1,\n",
        "            train_source, train_target, train_pred, train_prob,\n",
        "            val_source, val_target, val_pred, val_prob,\n",
        "        ]\n",
        "        log_table.add_data(*data)\n",
        "    \n",
        "    # Log the table at the end of the training\n",
        "    wandb.log({'Model predictions': log_table})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the models\n",
        "We can now finally train the models.\n",
        "Choose the right hyperparameters, play with them and try to find\n",
        "ones that lead to good models and good training curves.\n",
        "Try to reach a loss under 1.0.\n",
        "\n",
        "So you know, it is possible to get descent results with approximately 20 epochs.\n",
        "With CUDA enabled, one epoch, even on a big model with a big dataset, shouldn't last more than 10 minutes.\n",
        "A normal epoch is between 1 to 5 minutes.\n",
        "\n",
        "*This is considering Colab Pro, we should try using free Colab to get better estimations.*\n",
        "\n",
        "---\n",
        "\n",
        "To test your implementations, it is easier to try your models\n",
        "in a CPU instance. Indeed, Colab reduces your GPU instances priority\n",
        "with the time you recently past using GPU instances. It would be\n",
        "sad to consume all your GPU time on implementation testing.\n",
        "Moreover, you should try your models on small datasets and with a small number of parameters.\n",
        "For exemple, you could set:\n",
        "```\n",
        "MAX_SEQ_LEN = 10\n",
        "MIN_TOK_FREQ = 20\n",
        "dim_embedding = 40\n",
        "dim_hidden = 60\n",
        "n_layers = 1\n",
        "```\n",
        "\n",
        "You usually don't want to log anything onto WandB when testing your implementation.\n",
        "To deactivate WandB without having to change any line of code, you can type `!wandb offline` in a cell.\n",
        "\n",
        "Once you have rightly implemented the models, you can train bigger models on bigger datasets.\n",
        "When you do this, do not forget to change the runtime as GPU (and use `!wandb online`)!"
      ],
      "metadata": {
        "id": "YImgxCWjlWni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Checking GPU and logging to wandb\n",
        "\n",
        "!wandb login\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "WriScTUEsRHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c7402d-497d-4525-fa7b-a417157cc125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "Tue Apr 12 00:59:27 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciate the datasets\n",
        "\n",
        "MAX_SEQ_LEN = 60\n",
        "MIN_TOK_FREQ = 2\n",
        "train_dataset, val_dataset = build_datasets(\n",
        "    MAX_SEQ_LEN,\n",
        "    MIN_TOK_FREQ,\n",
        "    en_tokenizer,\n",
        "    fr_tokenizer,\n",
        "    train,\n",
        "    valid,\n",
        ")\n",
        "\n",
        "\n",
        "print(f'English vocabulary size: {len(train_dataset.en_vocab):,}')\n",
        "print(f'French vocabulary size: {len(train_dataset.fr_vocab):,}')\n",
        "\n",
        "print(f'\\nTraining examples: {len(train_dataset):,}')\n",
        "print(f'Validation examples: {len(val_dataset):,}')"
      ],
      "metadata": {
        "id": "iqmpxnO1lgDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfebc15f-4dfd-4b78-b309-532aa11e21e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English vocabulary size: 11,196\n",
            "French vocabulary size: 16,970\n",
            "\n",
            "Training examples: 173,104\n",
            "Validation examples: 19,235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Config map"
      ],
      "metadata": {
        "id": "29ic42_zmlfK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywFEpplOU5dn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1e99e8-b37f-4bd3-e3e3-f157cb917cd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type:depth-idx)                             Output Shape              Param #\n",
              "====================================================================================================\n",
              "TranslationTransformer                             --                        --\n",
              "├─Transformer: 1                                   --                        --\n",
              "│    └─TransformerEncoder: 2-2                     --                        --\n",
              "│    │    └─ModuleList: 3-1                        --                        768,108\n",
              "│    └─TransformerDecoder: 2                       --                        --\n",
              "│    │    └─ModuleList: 3-2                        --                        1,232,628\n",
              "├─Embedding: 1-1                                   [128, 60, 196]            2,194,416\n",
              "├─PositionalEncoding: 1-2                          [128, 60, 196]            --\n",
              "│    └─Dropout: 2-1                                [128, 60, 196]            --\n",
              "├─Transformer: 1                                   --                        --\n",
              "│    └─TransformerEncoder: 2-2                     --                        --\n",
              "│    │    └─ModuleList: 3-3                        --                        (recursive)\n",
              "├─Embedding: 1-3                                   [128, 60, 196]            3,326,120\n",
              "├─PositionalEncoding: 1-4                          [128, 60, 196]            --\n",
              "│    └─Dropout: 2-3                                [128, 60, 196]            --\n",
              "├─Transformer: 1-5                                 [128, 60, 196]            --\n",
              "├─Linear: 1-6                                      --                        3,343,090\n",
              "├─Sequential: 1-7                                  [128, 60, 16970]          --\n",
              "│    └─Linear: 2-4                                 [128, 60, 196]            38,612\n",
              "│    └─LeakyReLU: 2-5                              [128, 60, 196]            --\n",
              "│    └─LayerNorm: 2-6                              [128, 60, 196]            392\n",
              "│    └─Linear: 2-7                                 [128, 60, 196]            38,612\n",
              "│    └─LeakyReLU: 2-8                              [128, 60, 196]            --\n",
              "│    └─LayerNorm: 2-9                              [128, 60, 196]            392\n",
              "│    └─Linear: 2-10                                [128, 60, 196]            38,612\n",
              "│    └─LeakyReLU: 2-11                             [128, 60, 196]            --\n",
              "│    └─LayerNorm: 2-12                             [128, 60, 196]            392\n",
              "│    └─Linear: 2-13                                [128, 60, 16970]          3,343,090\n",
              "====================================================================================================\n",
              "Total params: 14,324,464\n",
              "Trainable params: 14,324,464\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.41\n",
              "====================================================================================================\n",
              "Input size (MB): 0.12\n",
              "Forward/backward pass size (MB): 1919.75\n",
              "Params size (MB): 57.30\n",
              "Estimated Total Size (MB): 1977.18\n",
              "===================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Build the model, the dataloaders, optimizer and the loss function\n",
        "# Log every hyperparameters and arguments into the config dictionnary\n",
        "\n",
        "# Model type \"RNN\"\n",
        "config = {\n",
        "    # General parameters\n",
        "    'epochs': 5,\n",
        "    'batch_size': 128,\n",
        "    'lr': 1e-3,\n",
        "    'betas': (0.9, 0.99),\n",
        "    'clip': 5,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "\n",
        "    # Model parameters\n",
        "    'n_tokens_src': len(train_dataset.en_vocab),\n",
        "    'n_tokens_tgt': len(train_dataset.fr_vocab),\n",
        "    'n_heads': 4,\n",
        "    'dim_embedding': 196,\n",
        "    'dim_hidden': 256,\n",
        "    'n_layers': 3,\n",
        "    'dropout': 0.1,\n",
        "    'model_type': 'RNN',\n",
        "\n",
        "    # Others\n",
        "    'max_sequence_length': MAX_SEQ_LEN,\n",
        "    'min_token_freq': MIN_TOK_FREQ,\n",
        "    'src_vocab': train_dataset.en_vocab,\n",
        "    'tgt_vocab': train_dataset.fr_vocab,\n",
        "    'src_tokenizer': en_tokenizer,\n",
        "    'tgt_tokenizer': fr_tokenizer,\n",
        "    'src_pad_idx': train_dataset.en_vocab['<pad>'],\n",
        "    'tgt_pad_idx': train_dataset.fr_vocab['<pad>'],\n",
        "    'seed': 0,\n",
        "    'log_every': 50,  # Number of batches between each wandb logs\n",
        "     'create_bar_chart': False\n",
        "}\n",
        "\n",
        "torch.manual_seed(config['seed'])\n",
        "\n",
        "config['train_loader'] = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "    collate_fn=lambda batch: generate_batch(batch, config['src_pad_idx'], config['tgt_pad_idx'])\n",
        ")\n",
        "\n",
        "config['val_loader'] = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "    collate_fn=lambda batch: generate_batch(batch, config['src_pad_idx'], config['tgt_pad_idx'])\n",
        ")\n",
        "# model = TranslationRNN(\n",
        "#     config['n_tokens_src'],\n",
        "#     config['n_tokens_tgt'],\n",
        "#     config['dim_embedding'],\n",
        "#     config['dim_hidden'],\n",
        "#     config['n_layers'],\n",
        "#     config['dropout'],\n",
        "#     config['src_pad_idx'],\n",
        "#     config['tgt_pad_idx'],\n",
        "#     config['model_type'],\n",
        "# )\n",
        "# Uncommented for testing\n",
        "model = TranslationTransformer(\n",
        "    config['n_tokens_src'],\n",
        "    config['n_tokens_tgt'],\n",
        "    config['n_heads'],\n",
        "    config['dim_embedding'],\n",
        "    config['dim_hidden'],\n",
        "    config['n_layers'],\n",
        "    config['dropout'],\n",
        "    config['src_pad_idx'],\n",
        "    config['tgt_pad_idx'],\n",
        ")\n",
        "#Replace the model to train here\n",
        "config['optimizer'] = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config['lr'],\n",
        "    betas=config['betas'],\n",
        ")\n",
        "\n",
        "weight_classes = torch.ones(config['n_tokens_tgt'], dtype=torch.float)\n",
        "weight_classes[config['tgt_vocab']['<unk>']] = 0.1  # Lower the importance of that class\n",
        "config['loss'] = nn.CrossEntropyLoss(\n",
        "    weight=weight_classes,\n",
        "    ignore_index=config['tgt_pad_idx'],  # We do not have to learn those\n",
        ")\n",
        "\n",
        "summary(\n",
        "    model,\n",
        "    input_size=[\n",
        "        (config['batch_size'], config['max_sequence_length']),\n",
        "        (config['batch_size'], config['max_sequence_length'])\n",
        "    ],\n",
        "    dtypes=[torch.long, torch.long],\n",
        "    depth=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import transformer\n",
        "#Testing\n",
        "train_loader= DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "    collate_fn=lambda batch: generate_batch(batch, config['src_pad_idx'], config['tgt_pad_idx'])\n",
        ")\n",
        "transformer = nn.Transformer()\n",
        "for batch_id, (source, target) in enumerate(train_loader):\n",
        "            print(source.shape)\n",
        "            print(target.shape)\n",
        "            \n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00jk2GPDo7Nh",
        "outputId": "39f03f96-22bc-4706-bb71-bc8f62ce534e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 18])\n",
            "torch.Size([128, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model, the dataloaders, optimizer and the loss function\n",
        "# Log every hyperparameters and arguments into the config dictionnary\n",
        "\n",
        "# Model type \"RNN\"\n",
        "config = {\n",
        "    # General parameters\n",
        "    'epochs': 5,\n",
        "    'batch_size': 128,\n",
        "    'lr': 1e-3,\n",
        "    'betas': (0.9, 0.99),\n",
        "    'clip': 5,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "\n",
        "    # Model parameters\n",
        "    'n_tokens_src': len(train_dataset.en_vocab),\n",
        "    'n_tokens_tgt': len(train_dataset.fr_vocab),\n",
        "    'n_heads': 4,\n",
        "    'dim_embedding': 196,\n",
        "    'dim_hidden': 256,\n",
        "    'n_layers': 3,\n",
        "    'dropout': 0.1,\n",
        "    'model_type': 'RNN',\n",
        "\n",
        "    # Others\n",
        "    'max_sequence_length': MAX_SEQ_LEN,\n",
        "    'min_token_freq': MIN_TOK_FREQ,\n",
        "    'src_vocab': train_dataset.en_vocab,\n",
        "    'tgt_vocab': train_dataset.fr_vocab,\n",
        "    'src_tokenizer': en_tokenizer,\n",
        "    'tgt_tokenizer': fr_tokenizer,\n",
        "    'src_pad_idx': train_dataset.en_vocab['<pad>'],\n",
        "    'tgt_pad_idx': train_dataset.fr_vocab['<pad>'],\n",
        "    'seed': 0,\n",
        "    'log_every': 50,  # Number of batches between each wandb logs\n",
        "}\n",
        "\n",
        "torch.manual_seed(config['seed'])\n",
        "\n",
        "config['train_loader'] = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "    collate_fn=lambda batch: generate_batch(batch, config['src_pad_idx'], config['tgt_pad_idx'])\n",
        ")\n",
        "\n",
        "config['val_loader'] = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "    collate_fn=lambda batch: generate_batch(batch, config['src_pad_idx'], config['tgt_pad_idx'])\n",
        ")\n",
        "\n",
        "# Uncommented for testing\n",
        "# model = TranslationTransformer(\n",
        "#     config['n_tokens_src'],\n",
        "#     config['n_tokens_tgt'],\n",
        "#     config['n_heads'],\n",
        "#     config['dim_embedding'],\n",
        "#     config['dim_hidden'],\n",
        "#     config['n_layers'],\n",
        "#     config['dropout'],\n",
        "#     config['src_pad_idx'],\n",
        "#     config['tgt_pad_idx'],\n",
        "# )\n"
      ],
      "metadata": {
        "id": "TWvrcohmy9mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Run  RNN**"
      ],
      "metadata": {
        "id": "7Xpz2fv_xqFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2l4W3Ke9zX_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TranslationRNN(\n",
        "    config['n_tokens_src'],\n",
        "    config['n_tokens_tgt'],\n",
        "    config['dim_embedding'],\n",
        "    config['dim_hidden'],\n",
        "    config['n_layers'],\n",
        "    config['dropout'],\n",
        "    config['src_pad_idx'],\n",
        "    config['tgt_pad_idx'],\n",
        "    config['model_type'],\n",
        ")\n",
        "\n",
        "#Replace the model to train here\n",
        "config['optimizer'] = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config['lr'],\n",
        "    betas=config['betas'],\n",
        ")\n",
        "\n",
        "weight_classes = torch.ones(config['n_tokens_tgt'], dtype=torch.float)\n",
        "weight_classes[config['tgt_vocab']['<unk>']] = 0.1  # Lower the importance of that class\n",
        "config['loss'] = nn.CrossEntropyLoss(\n",
        "    weight=weight_classes,\n",
        "    ignore_index=config['tgt_pad_idx'],  # We do not have to learn those\n",
        ")\n",
        "\n",
        "summary(\n",
        "    model,\n",
        "    input_size=[\n",
        "        (config['batch_size'], config['max_sequence_length']),\n",
        "        (config['batch_size'], config['max_sequence_length'])\n",
        "    ],\n",
        "    dtypes=[torch.long, torch.long],\n",
        "    depth=3,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sDyL01nzZBM",
        "outputId": "dfe55b54-2f20-4ebb-8a85-978df9e74305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "TranslationRNN                           --                        --\n",
              "├─RNN: 1                                 --                        --\n",
              "│    └─ModuleList: 2-1                   --                        --\n",
              "├─RNN: 1                                 --                        --\n",
              "│    └─ModuleList: 2-2                   --                        --\n",
              "├─Embedding: 1-1                         [128, 60, 196]            2,194,416\n",
              "├─RNN: 1-2                               [128, 60, 256]            --\n",
              "│    └─ModuleList: 2-1                   --                        --\n",
              "│    │    └─RNNCell: 3-1                 [128, 60, 256]            116,224\n",
              "│    │    └─RNNCell: 3-2                 [128, 60, 256]            131,584\n",
              "│    │    └─RNNCell: 3-3                 [128, 60, 256]            131,584\n",
              "├─LayerNorm: 1-3                         [128, 3, 256]             512\n",
              "├─Embedding: 1-4                         [128, 60, 196]            3,326,120\n",
              "├─RNN: 1-5                               [128, 60, 256]            --\n",
              "│    └─ModuleList: 2-2                   --                        --\n",
              "│    │    └─RNNCell: 3-4                 [128, 60, 256]            116,224\n",
              "│    │    └─RNNCell: 3-5                 [128, 60, 256]            131,584\n",
              "│    │    └─RNNCell: 3-6                 [128, 60, 256]            131,584\n",
              "├─Sequential: 1-6                        [128, 60, 16970]          --\n",
              "│    └─Linear: 2-3                       [128, 60, 256]            65,792\n",
              "│    └─LeakyReLU: 2-4                    [128, 60, 256]            --\n",
              "│    └─LayerNorm: 2-5                    [128, 60, 256]            512\n",
              "│    └─Linear: 2-6                       [128, 60, 256]            65,792\n",
              "│    └─LeakyReLU: 2-7                    [128, 60, 256]            --\n",
              "│    └─LayerNorm: 2-8                    [128, 60, 256]            512\n",
              "│    └─Linear: 2-9                       [128, 60, 256]            65,792\n",
              "│    └─LeakyReLU: 2-10                   [128, 60, 256]            --\n",
              "│    └─LayerNorm: 2-11                   [128, 60, 256]            512\n",
              "│    └─Linear: 2-12                      [128, 60, 16970]          4,361,290\n",
              "==========================================================================================\n",
              "Total params: 10,840,034\n",
              "Trainable params: 10,840,034\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 7.12\n",
              "==========================================================================================\n",
              "Input size (MB): 0.12\n",
              "Forward/backward pass size (MB): 1165.03\n",
              "Params size (MB): 43.36\n",
              "Estimated Total Size (MB): 1208.51\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "        group='RNN - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "        mode = 'disabled'\n",
        "    ):\n",
        "    train_model(model, config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "Gbkt-Pstxnc-",
        "outputId": "7d257f77-d1da-4c6c-cdcb-b13db4d3adb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.85     top-1: 0.47    top-5: 0.65    top-10: 0.70\n",
            "Eval -    loss: 2.67     top-1: 0.49    top-5: 0.67    top-10: 0.73\n",
            "Was Tom murdered?\n",
            "Tom est-il Tom ?\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 2.72     top-1: 0.50    top-5: 0.69    top-10: 0.74\n",
            "Eval -    loss: 2.42     top-1: 0.52    top-5: 0.71    top-10: 0.77\n",
            "Where did you stay?\n",
            "Où as-tu fait ?\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 2.31     top-1: 0.54    top-5: 0.72    top-10: 0.78\n",
            "Eval -    loss: 2.30     top-1: 0.53    top-5: 0.72    top-10: 0.78\n",
            "I was asked to wear a wire.\n",
            "J'ai dû prendre un cadeau.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 2.36     top-1: 0.52    top-5: 0.72    top-10: 0.79\n",
            "Eval -    loss: 2.23     top-1: 0.54    top-5: 0.74    top-10: 0.79\n",
            "I don't want you to leave.\n",
            "Je ne veux pas que tu restes.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 2.28     top-1: 0.53    top-5: 0.73    top-10: 0.79\n",
            "Eval -    loss: 2.18     top-1: 0.55    top-5: 0.74    top-10: 0.80\n",
            "They treat their employees well.\n",
            "Ils ont arrêté de fumer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I called my friend to say hi.\"\n",
        "\n",
        "preds = beam_search(\n",
        "    model,\n",
        "    sentence,\n",
        "    config['src_vocab'],\n",
        "    config['tgt_vocab'],\n",
        "    config['src_tokenizer'],\n",
        "    config['device'],\n",
        "    beam_width=10,\n",
        "    max_target=100,\n",
        "    max_sentence_length=config['max_sequence_length']\n",
        ")[:5]\n",
        "\n",
        "for i, (translation, likelihood) in enumerate(preds):\n",
        "    print(f'{i}. ({likelihood*100:.5f}%) \\t {translation}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqHvJT1tWcWD",
        "outputId": "c570b97f-94ee-4b39-e240-82ee26b27d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0. (0.18937%) \t J'ai fait ça pour moi.\n",
            "1. (0.16131%) \t J'ai fait mes devoirs.\n",
            "2. (0.13921%) \t J'ai pris mon argent pour moi.\n",
            "3. (0.12492%) \t J'ai fait mes devoirs pour moi.\n",
            "4. (0.10391%) \t J'ai pris mon parapluie.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I called my friend to say hi.\"\n",
        "pred1 = greedy_search(\n",
        "    model,\n",
        "    sentence,\n",
        "    config['src_vocab'],\n",
        "    config['tgt_vocab'],\n",
        "    config['src_tokenizer'],\n",
        "    config['device'],\n",
        "    config['max_sequence_length']\n",
        ")[0]\n",
        "\n",
        "print(f'({pred1[1]*100:.5f}%)       {pred1[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9LPRUdvuMGL",
        "outputId": "a34c0a8b-fb05-4589-ad82-46fd63f1c09a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.12492%)       J'ai fait mes devoirs pour moi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Run GRU**"
      ],
      "metadata": {
        "id": "lJgfB9bVx3b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config[\"model_type\"] = \"GRU\"\n",
        "\n",
        "model = TranslationRNN(\n",
        "    config['n_tokens_src'],\n",
        "    config['n_tokens_tgt'],\n",
        "    config['dim_embedding'],\n",
        "    config['dim_hidden'],\n",
        "    config['n_layers'],\n",
        "    config['dropout'],\n",
        "    config['src_pad_idx'],\n",
        "    config['tgt_pad_idx'],\n",
        "    config['model_type'],\n",
        ")\n",
        "\n",
        "#Replace the model to train here\n",
        "config['optimizer'] = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config['lr'],\n",
        "    betas=config['betas'],\n",
        ")\n",
        "\n",
        "weight_classes = torch.ones(config['n_tokens_tgt'], dtype=torch.float)\n",
        "weight_classes[config['tgt_vocab']['<unk>']] = 0.1  # Lower the importance of that class\n",
        "config['loss'] = nn.CrossEntropyLoss(\n",
        "    weight=weight_classes,\n",
        "    ignore_index=config['tgt_pad_idx'],  # We do not have to learn those\n",
        ")\n",
        "\n",
        "summary(\n",
        "    model,\n",
        "    input_size=[\n",
        "        (config['batch_size'], config['max_sequence_length']),\n",
        "        (config['batch_size'], config['max_sequence_length'])\n",
        "    ],\n",
        "    dtypes=[torch.long, torch.long],\n",
        "    depth=3,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14n25oRYy1CG",
        "outputId": "4ba688ab-fbbd-4a01-c34d-e9e4b1bd3c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "TranslationRNN                           --                        --\n",
              "├─GRU: 1                                 --                        --\n",
              "│    └─ModuleList: 2-1                   --                        --\n",
              "├─GRU: 1                                 --                        --\n",
              "│    └─ModuleList: 2-2                   --                        --\n",
              "├─Embedding: 1-1                         [128, 60, 196]            2,194,416\n",
              "├─GRU: 1-2                               [128, 60, 256]            --\n",
              "│    └─ModuleList: 2-1                   --                        --\n",
              "│    │    └─GRUCell: 3-1                 [128, 60, 256]            348,672\n",
              "│    │    └─GRUCell: 3-2                 [128, 60, 256]            394,752\n",
              "│    │    └─GRUCell: 3-3                 [128, 60, 256]            394,752\n",
              "├─LayerNorm: 1-3                         [128, 3, 256]             512\n",
              "├─Embedding: 1-4                         [128, 60, 196]            3,326,120\n",
              "├─GRU: 1-5                               [128, 60, 256]            --\n",
              "│    └─ModuleList: 2-2                   --                        --\n",
              "│    │    └─GRUCell: 3-4                 [128, 60, 256]            348,672\n",
              "│    │    └─GRUCell: 3-5                 [128, 60, 256]            394,752\n",
              "│    │    └─GRUCell: 3-6                 [128, 60, 256]            394,752\n",
              "├─Sequential: 1-6                        [128, 60, 16970]          --\n",
              "│    └─Linear: 2-3                       [128, 60, 256]            65,792\n",
              "│    └─LeakyReLU: 2-4                    [128, 60, 256]            --\n",
              "│    └─LayerNorm: 2-5                    [128, 60, 256]            512\n",
              "│    └─Linear: 2-6                       [128, 60, 256]            65,792\n",
              "│    └─LeakyReLU: 2-7                    [128, 60, 256]            --\n",
              "│    └─LayerNorm: 2-8                    [128, 60, 256]            512\n",
              "│    └─Linear: 2-9                       [128, 60, 256]            65,792\n",
              "│    └─LeakyReLU: 2-10                   [128, 60, 256]            --\n",
              "│    └─LayerNorm: 2-11                   [128, 60, 256]            512\n",
              "│    └─Linear: 2-12                      [128, 60, 16970]          4,361,290\n",
              "==========================================================================================\n",
              "Total params: 12,357,602\n",
              "Trainable params: 12,357,602\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 18.77\n",
              "==========================================================================================\n",
              "Input size (MB): 0.12\n",
              "Forward/backward pass size (MB): 1171.32\n",
              "Params size (MB): 49.43\n",
              "Estimated Total Size (MB): 1220.87\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "        group='GRU - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "        mode = 'disabled'\n",
        "    ):\n",
        "    train_model(model, config)\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "3ISKSNHLyW6_",
        "outputId": "7cfe78ea-6f11-48f1-bbb2-507e33a3b4e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.57     top-1: 0.50    top-5: 0.68    top-10: 0.75\n",
            "Eval -    loss: 2.62     top-1: 0.50    top-5: 0.68    top-10: 0.74\n",
            "I'm a new student.\n",
            "Je suis un peu en retard.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 2.34     top-1: 0.55    top-5: 0.73    top-10: 0.79\n",
            "Eval -    loss: 2.22     top-1: 0.55    top-5: 0.74    top-10: 0.79\n",
            "I read the whole book in a day.\n",
            "J'ai trouvé le livre ce matin.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 2.16     top-1: 0.55    top-5: 0.76    top-10: 0.81\n",
            "Eval -    loss: 2.03     top-1: 0.58    top-5: 0.77    top-10: 0.82\n",
            "Give me a beer.\n",
            "Donne-moi un œil.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 2.00     top-1: 0.57    top-5: 0.79    top-10: 0.84\n",
            "Eval -    loss: 1.88     top-1: 0.60    top-5: 0.79    top-10: 0.84\n",
            "Don't you remember my name?\n",
            "Ne me dis-tu pas mon nom ?\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 2.05     top-1: 0.57    top-5: 0.77    top-10: 0.82\n",
            "Eval -    loss: 1.79     top-1: 0.61    top-5: 0.81    top-10: 0.85\n",
            "This work is simple enough that even a child can do it.\n",
            "Ce livre est assez facile pour ne rien dire.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I called my friend to say hi.\"\n",
        "\n",
        "preds = beam_search(\n",
        "    model,\n",
        "    sentence,\n",
        "    config['src_vocab'],\n",
        "    config['tgt_vocab'],\n",
        "    config['src_tokenizer'],\n",
        "    config['device'],\n",
        "    beam_width=10,\n",
        "    max_target=100,\n",
        "    max_sentence_length=config['max_sequence_length']\n",
        ")[:5]\n",
        "\n",
        "for i, (translation, likelihood) in enumerate(preds):\n",
        "    print(f'{i}. ({likelihood*100:.5f}%) \\t {translation}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwfj-4eKWYTM",
        "outputId": "84f4baab-6fbb-405a-ef64-062cbc7d4a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0. (0.46880%) \t J'ai oublié mon nom.\n",
            "1. (0.40330%) \t J'ai oublié à ma mère.\n",
            "2. (0.38278%) \t J'ai répondu à ma mère.\n",
            "3. (0.26512%) \t J'ai laissé mon nom.\n",
            "4. (0.23090%) \t J'ai écrit mon nom.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I called my friend to say hi.\"\n",
        "pred1 = greedy_search(\n",
        "    model,\n",
        "    sentence,\n",
        "    config['src_vocab'],\n",
        "    config['tgt_vocab'],\n",
        "    config['src_tokenizer'],\n",
        "    config['device'],\n",
        "    config['max_sequence_length']\n",
        ")[0]\n",
        "\n",
        "print(f'({pred1[1]*100:.5f}%)       {pred1[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-TFT3ZcuSRX",
        "outputId": "60069883-f9c6-46cb-82d6-e0622728f00d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.02307%)       J'ai oublié mon nom à ton sujet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beam search"
      ],
      "metadata": {
        "id": "pn7PcZVh5EMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Run Transformer**"
      ],
      "metadata": {
        "id": "FllKwR1lxXoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TranslationTransformer(\n",
        "    config['n_tokens_src'],\n",
        "    config['n_tokens_tgt'],\n",
        "    config['n_heads'],\n",
        "    config['dim_embedding'],\n",
        "    config['dim_hidden'],\n",
        "    config['n_layers'],\n",
        "    config['dropout'],\n",
        "    config['src_pad_idx'],\n",
        "    config['tgt_pad_idx'],\n",
        ")\n",
        "\n",
        "config['optimizer'] = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config['lr'],\n",
        "    betas=config['betas'],\n",
        ")\n",
        "\n",
        "weight_classes = torch.ones(config['n_tokens_tgt'], dtype=torch.float)\n",
        "weight_classes[config['tgt_vocab']['<unk>']] = 0.1  # Lower the importance of that class\n",
        "config['loss'] = nn.CrossEntropyLoss(\n",
        "    weight=weight_classes,\n",
        "    ignore_index=config['tgt_pad_idx'],  # We do not have to learn those\n",
        ")\n",
        "\n",
        "summary(\n",
        "    model,\n",
        "    input_size=[\n",
        "        (config['batch_size'], config['max_sequence_length']),\n",
        "        (config['batch_size'], config['max_sequence_length'])\n",
        "    ],\n",
        "    dtypes=[torch.long, torch.long],\n",
        "    depth=3,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIZxX-FE4X-E",
        "outputId": "16c13c48-d99b-4a93-e8b1-ad108f82ce30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type:depth-idx)                             Output Shape              Param #\n",
              "====================================================================================================\n",
              "TranslationTransformer                             --                        --\n",
              "├─Transformer: 1                                   --                        --\n",
              "│    └─TransformerEncoder: 2-2                     --                        --\n",
              "│    │    └─ModuleList: 3-1                        --                        768,108\n",
              "│    └─TransformerDecoder: 2                       --                        --\n",
              "│    │    └─ModuleList: 3-2                        --                        1,232,628\n",
              "├─Embedding: 1-1                                   [128, 60, 196]            2,194,416\n",
              "├─PositionalEncoding: 1-2                          [128, 60, 196]            --\n",
              "│    └─Dropout: 2-1                                [128, 60, 196]            --\n",
              "├─Transformer: 1                                   --                        --\n",
              "│    └─TransformerEncoder: 2-2                     --                        --\n",
              "│    │    └─ModuleList: 3-3                        --                        (recursive)\n",
              "├─Embedding: 1-3                                   [128, 60, 196]            3,326,120\n",
              "├─PositionalEncoding: 1-4                          [128, 60, 196]            --\n",
              "│    └─Dropout: 2-3                                [128, 60, 196]            --\n",
              "├─Transformer: 1-5                                 [128, 60, 196]            --\n",
              "├─Linear: 1-6                                      --                        3,343,090\n",
              "├─Sequential: 1-7                                  [128, 60, 16970]          --\n",
              "│    └─Linear: 2-4                                 [128, 60, 196]            38,612\n",
              "│    └─LeakyReLU: 2-5                              [128, 60, 196]            --\n",
              "│    └─LayerNorm: 2-6                              [128, 60, 196]            392\n",
              "│    └─Linear: 2-7                                 [128, 60, 196]            38,612\n",
              "│    └─LeakyReLU: 2-8                              [128, 60, 196]            --\n",
              "│    └─LayerNorm: 2-9                              [128, 60, 196]            392\n",
              "│    └─Linear: 2-10                                [128, 60, 196]            38,612\n",
              "│    └─LeakyReLU: 2-11                             [128, 60, 196]            --\n",
              "│    └─LayerNorm: 2-12                             [128, 60, 196]            392\n",
              "│    └─Linear: 2-13                                [128, 60, 16970]          3,343,090\n",
              "====================================================================================================\n",
              "Total params: 14,324,464\n",
              "Trainable params: 14,324,464\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.41\n",
              "====================================================================================================\n",
              "Input size (MB): 0.12\n",
              "Forward/backward pass size (MB): 1919.75\n",
              "Params size (MB): 57.30\n",
              "Estimated Total Size (MB): 1977.18\n",
              "===================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maOTVtk4acxD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "5e6ebcd0-afc3-4ccc-d09a-69cec1ff2fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.27     top-1: 0.57    top-5: 0.76    top-10: 0.82\n",
            "Eval -    loss: 2.13     top-1: 0.59    top-5: 0.77    top-10: 0.82\n",
            "They already knew.\n",
            "Elles savais déjà.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.88     top-1: 0.63    top-5: 0.82    top-10: 0.86\n",
            "Eval -    loss: 1.72     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "I can't believe you're getting married.\n",
            "Je n'arrive pas à croire que tu sois marié.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.75     top-1: 0.64    top-5: 0.82    top-10: 0.87\n",
            "Eval -    loss: 1.52     top-1: 0.67    top-5: 0.86    top-10: 0.89\n",
            "This one's all yours.\n",
            "C'est tout le monde.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.63     top-1: 0.65    top-5: 0.85    top-10: 0.89\n",
            "Eval -    loss: 1.44     top-1: 0.68    top-5: 0.87    top-10: 0.90\n",
            "Go ahead!\n",
            "Allez !\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.36     top-1: 0.72    top-5: 0.88    top-10: 0.90\n",
            "Eval -    loss: 1.35     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "I thought you'd already done that.\n",
            "Je pensais que tu avais déjà fait ça.\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "with wandb.init(\n",
        "        config=config,\n",
        "        project='INF8225 - TP3',  # Title of your project\n",
        "        group='Transformer Translation - small',  # In what group of runs do you want this run to be in?\n",
        "        save_code=True,\n",
        "        mode = 'disabled'\n",
        "    ):\n",
        "    train_model(model, config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PFIyvKUefdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad424dc-7bfa-4bc5-ef96-6e1a0af85757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0. (2.80028%) \t J'ai appelé ma amie.\n",
            "1. (2.07530%) \t J'ai téléphoné à mon ami.\n",
            "2. (2.06449%) \t J'ai appelé mon ami.\n",
            "3. (1.99738%) \t J'ai appelé mon amie.\n",
            "4. (0.98363%) \t J'ai téléphoné à mon amie.\n"
          ]
        }
      ],
      "source": [
        "sentence = \"I called my friend to say hi.\"\n",
        "\n",
        "preds = beam_search(\n",
        "    model,\n",
        "    sentence,\n",
        "    config['src_vocab'],\n",
        "    config['tgt_vocab'],\n",
        "    config['src_tokenizer'],\n",
        "    config['device'],\n",
        "    beam_width=10,\n",
        "    max_target=100,\n",
        "    max_sentence_length=config['max_sequence_length']\n",
        ")[:5]\n",
        "\n",
        "for i, (translation, likelihood) in enumerate(preds):\n",
        "    print(f'{i}. ({likelihood*100:.5f}%) \\t {translation}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I called my friend to say hi.\"\n",
        "pred1 = greedy_search(\n",
        "    model,\n",
        "    sentence,\n",
        "    config['src_vocab'],\n",
        "    config['tgt_vocab'],\n",
        "    config['src_tokenizer'],\n",
        "    config['device'],\n",
        "    config['max_sequence_length']\n",
        ")[0]\n",
        "\n",
        "print(f'({pred1[1]*100:.5f}%)       {pred1[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4XholNXsB_u",
        "outputId": "d7c22e8b-1ab4-4e7c-c9c1-0b12ba4ad7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.84398%)       J'ai appelé mon ami à dire bonjour.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions\n",
        "1. Explain the differences between Vanilla RNN, GRU-RNN, and Transformers. \n",
        "2. Why is positionnal encoding necessary in Transformers and not in RNNs?\n",
        "3. Describe the preprocessing process. Detail how the initial dataset is processed before being fed to the translation models."
      ],
      "metadata": {
        "id": "uHhixEEGzWRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Small report - experiments\n",
        "Once everything is working fine, you can explore and do some little research work.\n",
        "\n",
        "For exemple, you can experiment with the hyperparameters.\n",
        "What are the effect of the differents hyperparameters with the final model performance? What about training time?\n",
        "\n",
        "What are some other metrics you could have for machine translation? Can you compute them and add them to your WandB report?\n",
        "\n",
        "Those are only examples, you can do whatever you think will be interesting.\n",
        "This part account for many points, *feel free to go wild!*\n",
        "\n",
        "---\n",
        "*Make a small report about your experiments here.*\n",
        "\n",
        "See report -\n",
        "Experiments"
      ],
      "metadata": {
        "id": "Y3tQdusIjPCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "def evaluate_blue_score(mod):\n",
        "    source = [s[0] for s in config[\"val_loader\"].dataset.dataset[:50]]\n",
        "    target =  [[s[1].split(\" \")] for s in config[\"val_loader\"].dataset.dataset[:50]]\n",
        "\n",
        "    pred = []\n",
        "    for sentence in source:\n",
        "        pred.append(beam_search(\n",
        "        mod,\n",
        "        sentence,\n",
        "        config['src_vocab'],\n",
        "        config['tgt_vocab'],\n",
        "        config['src_tokenizer'],\n",
        "        config['device'],\n",
        "        beam_width=1,\n",
        "        max_target=100,\n",
        "        max_sentence_length=config['max_sequence_length'])[0][0].split(\" \"))\n",
        "    return bleu_score(pred,target)\n"
      ],
      "metadata": {
        "id": "vNlD7wmLCYUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model, the dataloaders, optimizer and the loss function\n",
        "# Log every hyperparameters and arguments into the config dictionnary\n",
        "\n",
        "# Model type \"RNN\"\n",
        "config = {\n",
        "    # General parameters\n",
        "    'epochs': 5,\n",
        "    'batch_size': 128,\n",
        "    'lr': 1e-3,\n",
        "    'betas': (0.9, 0.99),\n",
        "    'clip': 5,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "\n",
        "    # Model parameters\n",
        "    'n_tokens_src': len(train_dataset.en_vocab),\n",
        "    'n_tokens_tgt': len(train_dataset.fr_vocab),\n",
        "    'n_heads': 4,\n",
        "    'dim_embedding': 196,\n",
        "    'dim_hidden': 256,\n",
        "    'n_layers': 3,\n",
        "    'dropout': 0.1,\n",
        "    'model_type': 'RNN',\n",
        "\n",
        "    # Others\n",
        "    'max_sequence_length': MAX_SEQ_LEN,\n",
        "    'min_token_freq': MIN_TOK_FREQ,\n",
        "    'src_vocab': train_dataset.en_vocab,\n",
        "    'tgt_vocab': train_dataset.fr_vocab,\n",
        "    'src_tokenizer': en_tokenizer,\n",
        "    'tgt_tokenizer': fr_tokenizer,\n",
        "    'src_pad_idx': train_dataset.en_vocab['<pad>'],\n",
        "    'tgt_pad_idx': train_dataset.fr_vocab['<pad>'],\n",
        "    'seed': 0,\n",
        "    'log_every': 50,  # Number of batches between each wandb logs\n",
        "    'create_bar_chart': True\n",
        "}\n",
        "\n",
        "torch.manual_seed(config['seed'])\n",
        "\n",
        "config['train_loader'] = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "    collate_fn=lambda batch: generate_batch(batch, config['src_pad_idx'], config['tgt_pad_idx'])\n",
        ")\n",
        "\n",
        "config['val_loader'] = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "    collate_fn=lambda batch: generate_batch(batch, config['src_pad_idx'], config['tgt_pad_idx'])\n",
        ")\n",
        "# model = TranslationRNN(\n",
        "#     config['n_tokens_src'],\n",
        "#     config['n_tokens_tgt'],\n",
        "#     config['dim_embedding'],\n",
        "#     config['dim_hidden'],\n",
        "#     config['n_layers'],\n",
        "#     config['dropout'],\n",
        "#     config['src_pad_idx'],\n",
        "#     config['tgt_pad_idx'],\n",
        "#     config['model_type'],\n",
        "# )\n",
        "# Uncommented for testing\n",
        "model = TranslationTransformer(\n",
        "    config['n_tokens_src'],\n",
        "    config['n_tokens_tgt'],\n",
        "    config['n_heads'],\n",
        "    config['dim_embedding'],\n",
        "    config['dim_hidden'],\n",
        "    config['n_layers'],\n",
        "    config['dropout'],\n",
        "    config['src_pad_idx'],\n",
        "    config['tgt_pad_idx'],\n",
        ")\n",
        "#Replace the model to train here\n",
        "config['optimizer'] = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config['lr'],\n",
        "    betas=config['betas'],\n",
        ")\n",
        "\n",
        "weight_classes = torch.ones(config['n_tokens_tgt'], dtype=torch.float)\n",
        "weight_classes[config['tgt_vocab']['<unk>']] = 0.1  # Lower the importance of that class\n",
        "config['loss'] = nn.CrossEntropyLoss(\n",
        "    weight=weight_classes,\n",
        "    ignore_index=config['tgt_pad_idx'],  # We do not have to learn those\n",
        ")\n"
      ],
      "metadata": {
        "id": "i5VxVdvX9OHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Analysis number of head**"
      ],
      "metadata": {
        "id": "fVBriTiG1jT_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxFnLwN1zI-h"
      },
      "outputs": [],
      "source": [
        "nhead_array = [2,4,7,14,28]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xUguuOBhiqNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "for head in nhead_array:\n",
        "    config[\"n_heads\"] = head\n",
        "\n",
        "    model = TranslationTransformer(\n",
        "    config['n_tokens_src'],\n",
        "    config['n_tokens_tgt'],\n",
        "    config['n_heads'],\n",
        "    config['dim_embedding'],\n",
        "    config['dim_hidden'],\n",
        "    config['n_layers'],\n",
        "    config['dropout'],\n",
        "    config['src_pad_idx'],\n",
        "    config['tgt_pad_idx']\n",
        "    )\n",
        "    config['optimizer'] = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config['lr'],\n",
        "    betas=config['betas'],\n",
        "    )\n",
        "    weight_classes = torch.ones(config['n_tokens_tgt'], dtype=torch.float)\n",
        "    weight_classes[config['tgt_vocab']['<unk>']] = 0.1  # Lower the importance of that class\n",
        "    config['loss'] = nn.CrossEntropyLoss(weight=weight_classes,ignore_index=config['tgt_pad_idx'] )\n",
        "    with wandb.init(\n",
        "            config=config,\n",
        "            project='INF8225 - TP3',  # Title of your project\n",
        "            group='Transformer - Number of head experiments',  # In what group of runs do you want this run to be in?\n",
        "            save_code=True,\n",
        "            mode = 'online',\n",
        "            name = \"Transformer with \"+str(head)+ \" heads\"\n",
        "        ):\n",
        "        train_model(model, config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f763af245f6c4450bd2a5ea079d598d8",
            "b34abb9b92ed43279ffa1ee70a7357e2",
            "1bb59ac705a1400f940b246095711ffb",
            "67ac515c98e84bff9f98ba5d84b1a687",
            "c1daf2c3b02646eda84ba8a9ef9a31df",
            "db5c960935b54746812aee44ac0c8ac6",
            "090e3ebc7f9144099e67bf04dfbc73bb",
            "d4e9cec2424b4eb1a3b5b88bfb040982",
            "4df2676466f24e7bb4395581ea19ac67",
            "b31687a101e84e7e8db4d8aed7283f63",
            "527aa8ae789c4244814e54fd989c07ec",
            "65255b7d1bcf46dca09fa742cadbad64",
            "6eb0daa906ca4f9eaf2e4997d563359d",
            "3e0e5ade65ee4d7b81bc037b19efe2d7",
            "af6762c918324791a710c108fe84f866",
            "53203386db6140e6aabe2770c39b833f",
            "c77aca43269c444ea232eb852fb0255c",
            "22715b7ebe7c442ab80043cbf53e65cc",
            "03dd9450de02483680ce6d67455b7646",
            "4125b2a384f941eca8b97dee0b06b206",
            "d78e1969603745f09fe31cf14bc52307",
            "829ed0d87ea840d7a3be9de674e68c9c",
            "2d83fd14ea8143758d415bdb95b3dd9e",
            "d6ffc0355a4240fba98d9eba46c11672",
            "bfb75821be6648a5b64825c0adafd6ad",
            "49996d04a0c5454ca53ac0d9a8c7a2c1",
            "9367888f4b414d829edad7f7df3bec6f",
            "57fa10f5ea85447b960c4dd3de0ec3f0",
            "7a99863768e24872973f200a4adc6eb5",
            "7cdb95624d4f435ebbb13fcb88f1a127",
            "f4ed5d5c53e24e9fa34907c51a5a16e7",
            "cb1022b693cb444191a49434c0fae9c8",
            "0480313ab8c347da9448c91fc3206352",
            "efe8ac50436b4788a13bbc0e07733092",
            "1d718c20d10948bfbd46dbca31067233",
            "ef8e797ba12748a789a71f1d420ca278",
            "64b638506bfc45c8a57f9477bc5b5acf",
            "8679de21d94449a9abb3a603ae25eecc",
            "b8ba57fbd0a447609ef09b0f026118e5",
            "b18eb3938f9c4c45a756c871ef136f9c"
          ]
        },
        "id": "eEqsI4br6ERH",
        "outputId": "dea7702f-d8af-41d4-eb7d-2e952e680374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220411_202655-353jsik7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/353jsik7\" target=\"_blank\">Transformer with 2 heads</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.34     top-1: 0.55    top-5: 0.75    top-10: 0.80\n",
            "Eval -    loss: 2.18     top-1: 0.58    top-5: 0.77    top-10: 0.81\n",
            "What season do you like the best?\n",
            "Qu'est-ce que tu aimes le meilleur ?\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 2.02     top-1: 0.60    top-5: 0.79    top-10: 0.84\n",
            "Eval -    loss: 1.76     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "I suppose everyone thinks I'm being a little too picky.\n",
            "Je suppose que tout le monde pense.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.67     top-1: 0.62    top-5: 0.84    top-10: 0.88\n",
            "Eval -    loss: 1.56     top-1: 0.67    top-5: 0.85    top-10: 0.89\n",
            "Did you do your work?\n",
            "Avez-vous fait du travail ?\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.64     top-1: 0.64    top-5: 0.85    top-10: 0.89\n",
            "Eval -    loss: 1.46     top-1: 0.68    top-5: 0.86    top-10: 0.90\n",
            "You have a great alibi.\n",
            "Tu as un grand alibi.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.45     top-1: 0.69    top-5: 0.87    top-10: 0.91\n",
            "Eval -    loss: 1.37     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "I can't believe you're trying to bribe me.\n",
            "Je n'arrive pas à croire que tu essaies de me suivre.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.304 MB of 0.304 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f763af245f6c4450bd2a5ea079d598d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▃▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.44645</td></tr><tr><td>Train - top-1</td><td>0.68537</td></tr><tr><td>Train - top-10</td><td>0.91106</td></tr><tr><td>Train - top-5</td><td>0.87396</td></tr><tr><td>Validation - loss</td><td>1.36722</td></tr><tr><td>Validation - top-1</td><td>0.69596</td></tr><tr><td>Validation - top-10</td><td>0.90891</td></tr><tr><td>Validation - top-5</td><td>0.87555</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Transformer with 2 heads</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/353jsik7\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/353jsik7</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220411_202655-353jsik7/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220411_203854-20hq6tln</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/20hq6tln\" target=\"_blank\">Transformer with 4 heads</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.30     top-1: 0.57    top-5: 0.76    top-10: 0.80\n",
            "Eval -    loss: 2.15     top-1: 0.58    top-5: 0.77    top-10: 0.82\n",
            "She is constantly writing letters.\n",
            "Elle est fatigué.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.97     top-1: 0.60    top-5: 0.81    top-10: 0.85\n",
            "Eval -    loss: 1.72     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "I felt relieved when my plane landed safely.\n",
            "Je me suis sentie quand mon avion.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.59     top-1: 0.66    top-5: 0.85    top-10: 0.88\n",
            "Eval -    loss: 1.53     top-1: 0.67    top-5: 0.86    top-10: 0.89\n",
            "I told myself to stay positive.\n",
            "J'ai dit de rester seul.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.70     top-1: 0.65    top-5: 0.83    top-10: 0.87\n",
            "Eval -    loss: 1.42     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "I told Tom that he shouldn't go out after dark.\n",
            "Je lui ai dit qu'il ne devrait pas sortir.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.29     top-1: 0.72    top-5: 0.89    top-10: 0.92\n",
            "Eval -    loss: 1.35     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Two weeks have passed and I haven't seen you.\n",
            "Deux semaines, je ne vous ai pas vus.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.316 MB of 0.316 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4df2676466f24e7bb4395581ea19ac67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▇▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.28873</td></tr><tr><td>Train - top-1</td><td>0.7229</td></tr><tr><td>Train - top-10</td><td>0.92235</td></tr><tr><td>Train - top-5</td><td>0.88953</td></tr><tr><td>Validation - loss</td><td>1.35465</td></tr><tr><td>Validation - top-1</td><td>0.69873</td></tr><tr><td>Validation - top-10</td><td>0.90933</td></tr><tr><td>Validation - top-5</td><td>0.87757</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Transformer with 4 heads</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/20hq6tln\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/20hq6tln</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220411_203854-20hq6tln/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220411_205059-61n7yhw9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/61n7yhw9\" target=\"_blank\">Transformer with 7 heads</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.30     top-1: 0.57    top-5: 0.77    top-10: 0.82\n",
            "Eval -    loss: 2.15     top-1: 0.58    top-5: 0.77    top-10: 0.82\n",
            "He lost his job.\n",
            "Il a perdu son travail.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.97     top-1: 0.62    top-5: 0.81    top-10: 0.85\n",
            "Eval -    loss: 1.72     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "We were both afraid to talk.\n",
            "Nous avons peur de parler tous les deux.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.56     top-1: 0.66    top-5: 0.86    top-10: 0.90\n",
            "Eval -    loss: 1.52     top-1: 0.67    top-5: 0.86    top-10: 0.89\n",
            "Everyone always asks me that.\n",
            "Tout le monde me fait toujours ainsi.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.54     top-1: 0.68    top-5: 0.86    top-10: 0.90\n",
            "Eval -    loss: 1.41     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "Who hates you?\n",
            "Qui vous déteste ?\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.40     top-1: 0.69    top-5: 0.88    top-10: 0.91\n",
            "Eval -    loss: 1.35     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Tom doesn't have a dad.\n",
            "Tom n'a pas de père.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.327 MB of 0.327 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c77aca43269c444ea232eb852fb0255c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▇▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.40212</td></tr><tr><td>Train - top-1</td><td>0.68969</td></tr><tr><td>Train - top-10</td><td>0.91432</td></tr><tr><td>Train - top-5</td><td>0.88082</td></tr><tr><td>Validation - loss</td><td>1.34529</td></tr><tr><td>Validation - top-1</td><td>0.70068</td></tr><tr><td>Validation - top-10</td><td>0.90958</td></tr><tr><td>Validation - top-5</td><td>0.87811</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Transformer with 7 heads</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/61n7yhw9\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/61n7yhw9</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220411_205059-61n7yhw9/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220411_210318-19ryidc8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/19ryidc8\" target=\"_blank\">Transformer with 14 heads</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.33     top-1: 0.56    top-5: 0.76    top-10: 0.80\n",
            "Eval -    loss: 2.13     top-1: 0.58    top-5: 0.77    top-10: 0.82\n",
            "We must leave right away.\n",
            "Nous devons continuer.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.78     top-1: 0.63    top-5: 0.83    top-10: 0.87\n",
            "Eval -    loss: 1.72     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "They look bored.\n",
            "Ils ont l'air.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.53     top-1: 0.68    top-5: 0.86    top-10: 0.90\n",
            "Eval -    loss: 1.52     top-1: 0.67    top-5: 0.86    top-10: 0.89\n",
            "All of the students have to wear the same uniform.\n",
            "Tous les élèves doivent porter les étudiants.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.59     top-1: 0.66    top-5: 0.86    top-10: 0.90\n",
            "Eval -    loss: 1.40     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "Tom knows that's true.\n",
            "Tom connaît ça vrai.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.42     top-1: 0.69    top-5: 0.87    top-10: 0.91\n",
            "Eval -    loss: 1.33     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Don't cross the road while the signal is red.\n",
            "Ne gaspillez pas le prochain train.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.340 MB of 0.340 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfb75821be6648a5b64825c0adafd6ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▄▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.41557</td></tr><tr><td>Train - top-1</td><td>0.68884</td></tr><tr><td>Train - top-10</td><td>0.91127</td></tr><tr><td>Train - top-5</td><td>0.86959</td></tr><tr><td>Validation - loss</td><td>1.32616</td></tr><tr><td>Validation - top-1</td><td>0.70283</td></tr><tr><td>Validation - top-10</td><td>0.91185</td></tr><tr><td>Validation - top-5</td><td>0.88032</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Transformer with 14 heads</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/19ryidc8\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/19ryidc8</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220411_210318-19ryidc8/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220411_211609-35y6x8s8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/35y6x8s8\" target=\"_blank\">Transformer with 28 heads</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.24     top-1: 0.56    top-5: 0.75    top-10: 0.81\n",
            "Eval -    loss: 2.14     top-1: 0.58    top-5: 0.77    top-10: 0.82\n",
            "He always borrows money from me.\n",
            "Il me prend toujours d'argent.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.87     top-1: 0.62    top-5: 0.83    top-10: 0.86\n",
            "Eval -    loss: 1.70     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "Show me another tie, please.\n",
            "Montre-moi une autre cravate, s'il vous plaît.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.68     top-1: 0.65    top-5: 0.85    top-10: 0.88\n",
            "Eval -    loss: 1.53     top-1: 0.67    top-5: 0.85    top-10: 0.89\n",
            "I remember you.\n",
            "Je me rappelle vous.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.68     top-1: 0.63    top-5: 0.84    top-10: 0.88\n",
            "Eval -    loss: 1.41     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "What did you hope to find?\n",
            "Comment as-tu trouvé ?\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.34     top-1: 0.69    top-5: 0.88    top-10: 0.92\n",
            "Eval -    loss: 1.34     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Where are my slippers?\n",
            "Où sont mes pantoufles ?\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.352 MB of 0.352 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0480313ab8c347da9448c91fc3206352"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇█▇██▇███████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇███████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.33799</td></tr><tr><td>Train - top-1</td><td>0.68647</td></tr><tr><td>Train - top-10</td><td>0.92148</td></tr><tr><td>Train - top-5</td><td>0.88163</td></tr><tr><td>Validation - loss</td><td>1.34482</td></tr><tr><td>Validation - top-1</td><td>0.69937</td></tr><tr><td>Validation - top-10</td><td>0.91015</td></tr><tr><td>Validation - top-5</td><td>0.87903</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Transformer with 28 heads</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/35y6x8s8\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/35y6x8s8</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220411_211609-35y6x8s8/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le nombre de tête n'affecte pas les performances."
      ],
      "metadata": {
        "id": "JDgw4Shv0WUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Varying the embedding size**\n",
        "\n"
      ],
      "metadata": {
        "id": "89DAdjlkTxwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    # General parameters\n",
        "    'epochs': 5,\n",
        "    'batch_size': 128,\n",
        "    'lr': 1e-3,\n",
        "    'betas': (0.9, 0.99),\n",
        "    'clip': 5,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "\n",
        "    # Model parameters\n",
        "    'n_tokens_src': len(train_dataset.en_vocab),\n",
        "    'n_tokens_tgt': len(train_dataset.fr_vocab),\n",
        "    'n_heads': 4,\n",
        "    'dim_embedding': 196,\n",
        "    'dim_hidden': 256,\n",
        "    'n_layers': 3,\n",
        "    'dropout': 0.1,\n",
        "    'model_type': 'RNN',\n",
        "\n",
        "    # Others\n",
        "    'max_sequence_length': MAX_SEQ_LEN,\n",
        "    'min_token_freq': MIN_TOK_FREQ,\n",
        "    'src_vocab': train_dataset.en_vocab,\n",
        "    'tgt_vocab': train_dataset.fr_vocab,\n",
        "    'src_tokenizer': en_tokenizer,\n",
        "    'tgt_tokenizer': fr_tokenizer,\n",
        "    'src_pad_idx': train_dataset.en_vocab['<pad>'],\n",
        "    'tgt_pad_idx': train_dataset.fr_vocab['<pad>'],\n",
        "    'seed': 0,\n",
        "    'log_every': 50,  # Number of batches between each wandb logs\n",
        "     'create_bar_chart': False\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "pmGgT6pn9qqN",
        "outputId": "d8093eee-8b4e-4705-d9d1-345cce8f79cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-6c7773b34368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;34m'n_tokens_src'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m'n_tokens_tgt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfr_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m'n_heads'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RNN & GRU"
      ],
      "metadata": {
        "id": "gZUBtJvTHce6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_type in [\"RNN\",\"GRU\"]:\n",
        "    for emb_size in [100,160, 180,196]:\n",
        "            config['dim_embedding'] = emb_size\n",
        "            config['model_type'] = model_type\n",
        "            model = TranslationRNN(\n",
        "                config['n_tokens_src'],\n",
        "                config['n_tokens_tgt'],\n",
        "                config['dim_embedding'],\n",
        "                config['dim_hidden'],\n",
        "                config['n_layers'],\n",
        "                config['dropout'],\n",
        "                config['src_pad_idx'],\n",
        "                config['tgt_pad_idx'],\n",
        "                config['model_type'],\n",
        "            )\n",
        "            model.train()\n",
        "\n",
        "\n",
        "            #Replace the model to train here\n",
        "            config['optimizer'] = optim.Adam(\n",
        "                model.parameters(),\n",
        "                lr=config['lr'],\n",
        "                betas=config['betas'],\n",
        "            )\n",
        "\n",
        "            weight_classes = torch.ones(config['n_tokens_tgt'], dtype=torch.float)\n",
        "            weight_classes[config['tgt_vocab']['<unk>']] = 0.1  # Lower the importance of that class\n",
        "            config['loss'] = nn.CrossEntropyLoss(\n",
        "                weight=weight_classes,\n",
        "                ignore_index=config['tgt_pad_idx'],  # We do not have to learn those\n",
        "            )\n",
        "\n",
        "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "            with wandb.init(\n",
        "                    config=config,\n",
        "                    project='INF8225 - TP3',  # Title of your project\n",
        "                    group='Embedding size',  # In what group of runs do you want this run to be in?\n",
        "                    save_code=True,\n",
        "                    mode = 'offline',\n",
        "                    name = model_type + \" emb_size:\" + emb_size\n",
        "                ):\n",
        "                train_model(model, config)\n",
        "                wandb.log({\"bleu_score\":evaluate_blue_score(model)})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598,
          "referenced_widgets": [
            "ee11e7173a78439d957e9243c787bb4d",
            "d3e8a4d68bdd444ba4c2323b328f7383",
            "4b18623eb7484997a22ac2dd022b2d70",
            "9976b7e5f37e4a13b56177d990002e72",
            "0c8e299b2b74455ea1160fce5d17fc8f",
            "468d51a185fe46c8a734d11cadf33961",
            "c02966f8919c4334bd9a680993cb8a82",
            "db35367d3ab74b80bd49db331f5bd797"
          ]
        },
        "id": "jBglWrnFHlCs",
        "outputId": "e2f3a4a7-a931-43d3-a06b-d5429ca1e516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee11e7173a78439d957e9243c787bb4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "You can sync this run to the cloud by running:<br/><code>wandb sync /content/wandb/offline-run-20220412_004729-xcy7juae<code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/offline-run-20220412_004729-xcy7juae/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-10ac6a91db77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'offline'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 ):\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"bleu_score\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mevaluate_blue_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-153-a32f9e84013b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, config)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformer"
      ],
      "metadata": {
        "id": "CA1ISoYwTR4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for emb_size in [100,160,180,196]:\n",
        "    config[\"dim_embedding\"] = emb_size\n",
        "    config['n_heads'] = 4\n",
        "    model = TranslationTransformer(\n",
        "    config['n_tokens_src'],\n",
        "    config['n_tokens_tgt'],\n",
        "    config['n_heads'],\n",
        "    config['dim_embedding'],\n",
        "    config['dim_hidden'],\n",
        "    config['n_layers'],\n",
        "    config['dropout'],\n",
        "    config['src_pad_idx'],\n",
        "    config['tgt_pad_idx']\n",
        "    )\n",
        "    config['optimizer'] = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config['lr'],\n",
        "    betas=config['betas'],\n",
        "    )\n",
        "    weight_classes = torch.ones(config['n_tokens_tgt'], dtype=torch.float)\n",
        "    weight_classes[config['tgt_vocab']['<unk>']] = 0.1  # Lower the importance of that class\n",
        "    config['loss'] = nn.CrossEntropyLoss(weight=weight_classes,ignore_index=config['tgt_pad_idx'] )\n",
        "    with wandb.init(\n",
        "            config=config,\n",
        "            project='INF8225 - TP3',  # Title of your project\n",
        "            group='Transformer - emb_size',  # In what group of runs do you want this run to be in?\n",
        "            save_code=True,\n",
        "            mode = 'online',\n",
        "            name = \"Transformer with \"+ str(emb_size)\n",
        "        ):\n",
        "        train_model(model, config)\n",
        "        wandb.log({\"bleu_score\":evaluate_blue_score(model)})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d3ed53664c2d404c99898497431494f2",
            "ec8e927886014db487c3e8dbdc4b7362",
            "2e1d718d53654990b4ad5aecfd2d2a79",
            "468d69895f304b88b964b528ed19e0f6",
            "2296a31bdb3b46639c25df7bedff9064",
            "1fe03f97c7834bbb8d1a97f268201308",
            "74509423b4ac4c85ae9f8f68d6446b34",
            "94fe720bf5b44694b4aad1de22a4f300",
            "c46332c7e13f4c299b863161744c3e0e",
            "ce450584520541ee9fbd5e50c339ac87",
            "7fe1bdcf116449b99ffcf36773724194",
            "50c5e0180a564d56b4ea7b8315e42f8c",
            "3a181949177e43db9b5a73a1fd2d7b39",
            "24d0e9d5b9394d84b6c9b1dbf12ced42",
            "1239f709d9e9489b92087e3cc9e02dd6",
            "7489ca3405f442a0973f0012b8148dbe",
            "e592031de9b94c76af11d03c9507434a",
            "803ca61e9b344561a34b001dc404eea8",
            "fd0cab687007439cb11aa1f9b68fbb37",
            "b5777eecf7c746208b73a976a98b5ba0",
            "6f964857f53644b486f5a0f499f12ffa",
            "dce4ad9220d6451096d655e34c9ed6da",
            "7fe649f48f16443491b28fac4b907189",
            "8328b3035cb24325bdb774c303c3c719",
            "4f3c29a65a0f44b2af4df837bf6638e8",
            "798fc758e1804ecd8a462f8919e3386a",
            "4329dc6fb0ab416db36d307bba7071f5",
            "d366e38235974ae2be2e54af18b7130a",
            "44f12917a6de4d89bac2737c1dc05cb7",
            "af9a210c76894320927c6db6725868bc",
            "6268c0d2380f49bca42d094fab4a467c",
            "2b5560c94b874e44b0d3a030a5478124"
          ]
        },
        "id": "lY412SGPIWFs",
        "outputId": "0e52528e-6e05-49a4-b58c-20758ee4a2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220412_011428-25vjoaem</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/25vjoaem\" target=\"_blank\">Transformer with 100</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.83     top-1: 0.49    top-5: 0.69    top-10: 0.74\n",
            "Eval -    loss: 2.63     top-1: 0.51    top-5: 0.70    top-10: 0.75\n",
            "I love this view.\n",
            "J'adore ceci.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 2.28     top-1: 0.57    top-5: 0.76    top-10: 0.81\n",
            "Eval -    loss: 2.10     top-1: 0.59    top-5: 0.78    top-10: 0.82\n",
            "Don't talk to me about work.\n",
            "Ne me parle pas.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.81     top-1: 0.62    top-5: 0.83    top-10: 0.87\n",
            "Eval -    loss: 1.84     top-1: 0.62    top-5: 0.81    top-10: 0.86\n",
            "Tom could hardly speak French at all when I first met him.\n",
            "Je n'ai pas pu parler quand Tom puisse le français.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 2.18     top-1: 0.56    top-5: 0.78    top-10: 0.82\n",
            "Eval -    loss: 1.69     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "I don't want anything more.\n",
            "Je ne veux rien.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.79     top-1: 0.63    top-5: 0.83    top-10: 0.88\n",
            "Eval -    loss: 1.60     top-1: 0.66    top-5: 0.85    top-10: 0.88\n",
            "You're stalling.\n",
            "Vous êtes invités.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.330 MB of 0.330 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3ed53664c2d404c99898497431494f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>Train - top-5</td><td>▁▃▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▇▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▆▇█</td></tr><tr><td>bleu_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.7946</td></tr><tr><td>Train - top-1</td><td>0.62901</td></tr><tr><td>Train - top-10</td><td>0.87626</td></tr><tr><td>Train - top-5</td><td>0.82608</td></tr><tr><td>Validation - loss</td><td>1.59504</td></tr><tr><td>Validation - top-1</td><td>0.66133</td></tr><tr><td>Validation - top-10</td><td>0.88389</td></tr><tr><td>Validation - top-5</td><td>0.84666</td></tr><tr><td>bleu_score</td><td>0.16249</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Transformer with 100</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/25vjoaem\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/25vjoaem</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220412_011428-25vjoaem/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220412_012432-jn2iris6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/jn2iris6\" target=\"_blank\">Transformer with 160</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.45     top-1: 0.54    top-5: 0.74    top-10: 0.79\n",
            "Eval -    loss: 2.29     top-1: 0.56    top-5: 0.75    top-10: 0.80\n",
            "Tom misled me.\n",
            "Tom m'a menti.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.93     top-1: 0.62    top-5: 0.80    top-10: 0.85\n",
            "Eval -    loss: 1.81     top-1: 0.63    top-5: 0.82    top-10: 0.86\n",
            "Where did you buy it?\n",
            "Où l'ai-tu acheté ?\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.76     top-1: 0.65    top-5: 0.84    top-10: 0.87\n",
            "Eval -    loss: 1.61     top-1: 0.66    top-5: 0.84    top-10: 0.88\n",
            "The place was almost empty.\n",
            "La place était presque vide.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.59     top-1: 0.66    top-5: 0.86    top-10: 0.90\n",
            "Eval -    loss: 1.49     top-1: 0.68    top-5: 0.86    top-10: 0.90\n",
            "Would you lend me your pen?\n",
            "Voudrais-tu me prêter votre stylo   ?\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.52     top-1: 0.67    top-5: 0.85    top-10: 0.90\n",
            "Eval -    loss: 1.41     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "Do you have relatives here?\n",
            "Avez-vous des idées ici ?\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.342 MB of 0.342 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c46332c7e13f4c299b863161744c3e0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▃▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▇▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▆▇█</td></tr><tr><td>bleu_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.51912</td></tr><tr><td>Train - top-1</td><td>0.67</td></tr><tr><td>Train - top-10</td><td>0.89847</td></tr><tr><td>Train - top-5</td><td>0.85018</td></tr><tr><td>Validation - loss</td><td>1.41499</td></tr><tr><td>Validation - top-1</td><td>0.68847</td></tr><tr><td>Validation - top-10</td><td>0.9037</td></tr><tr><td>Validation - top-5</td><td>0.87019</td></tr><tr><td>bleu_score</td><td>0.27444</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Transformer with 160</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/jn2iris6\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/jn2iris6</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220412_012432-jn2iris6/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220412_013549-yq8dorhq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/yq8dorhq\" target=\"_blank\">Transformer with 180</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.33     top-1: 0.56    top-5: 0.75    top-10: 0.80\n",
            "Eval -    loss: 2.19     top-1: 0.58    top-5: 0.77    top-10: 0.81\n",
            "She asked me about my mother.\n",
            "Elle m'a demandé de mon mère.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.94     top-1: 0.61    top-5: 0.80    top-10: 0.86\n",
            "Eval -    loss: 1.75     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "We should leave immediately.\n",
            "Nous devrions partir immédiatement.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.61     top-1: 0.66    top-5: 0.84    top-10: 0.88\n",
            "Eval -    loss: 1.56     top-1: 0.67    top-5: 0.85    top-10: 0.89\n",
            "I've promised Tom that I would help.\n",
            "J'espère que j'aiderais Tom.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.65     top-1: 0.64    top-5: 0.84    top-10: 0.89\n",
            "Eval -    loss: 1.44     top-1: 0.68    top-5: 0.87    top-10: 0.90\n",
            "If you want to come, you can.\n",
            "Si tu veux venir, tu peux venir.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.46     top-1: 0.66    top-5: 0.87    top-10: 0.90\n",
            "Eval -    loss: 1.37     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Tom does love you.\n",
            "Tom t'aime.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.354 MB of 0.354 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e592031de9b94c76af11d03c9507434a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▃▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▇▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▆▇█</td></tr><tr><td>bleu_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.4591</td></tr><tr><td>Train - top-1</td><td>0.65561</td></tr><tr><td>Train - top-10</td><td>0.89885</td></tr><tr><td>Train - top-5</td><td>0.8654</td></tr><tr><td>Validation - loss</td><td>1.367</td></tr><tr><td>Validation - top-1</td><td>0.69644</td></tr><tr><td>Validation - top-10</td><td>0.9079</td></tr><tr><td>Validation - top-5</td><td>0.87552</td></tr><tr><td>bleu_score</td><td>0.173</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Transformer with 180</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/yq8dorhq\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/yq8dorhq</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220412_013549-yq8dorhq/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220412_014728-2hf6l7ml</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/2hf6l7ml\" target=\"_blank\">Transformer with 196</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.53     top-1: 0.54    top-5: 0.73    top-10: 0.79\n",
            "Eval -    loss: 2.17     top-1: 0.58    top-5: 0.77    top-10: 0.82\n",
            "Tom convinced Mary.\n",
            "Tom a mis Marie.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.75     top-1: 0.64    top-5: 0.84    top-10: 0.88\n",
            "Eval -    loss: 1.73     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "Do you like white chocolate?\n",
            "Aimez-vous en blanc ?\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.70     top-1: 0.64    top-5: 0.84    top-10: 0.88\n",
            "Eval -    loss: 1.54     top-1: 0.67    top-5: 0.85    top-10: 0.89\n",
            "I'd like to talk with you.\n",
            "J'aimerais vous parler.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.52     top-1: 0.66    top-5: 0.86    top-10: 0.90\n",
            "Eval -    loss: 1.42     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "I've decided to go by train.\n",
            "J'ai décidé d'y aller en train.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.38     top-1: 0.69    top-5: 0.88    top-10: 0.91\n",
            "Eval -    loss: 1.35     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "When will we leave?\n",
            "Quand partons-nous ?\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.365 MB of 0.365 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f3c29a65a0f44b2af4df837bf6638e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▆▇█</td></tr><tr><td>bleu_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.37525</td></tr><tr><td>Train - top-1</td><td>0.68914</td></tr><tr><td>Train - top-10</td><td>0.91466</td></tr><tr><td>Train - top-5</td><td>0.88406</td></tr><tr><td>Validation - loss</td><td>1.3472</td></tr><tr><td>Validation - top-1</td><td>0.6992</td></tr><tr><td>Validation - top-10</td><td>0.9101</td></tr><tr><td>Validation - top-5</td><td>0.8781</td></tr><tr><td>bleu_score</td><td>0.20832</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Transformer with 196</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/2hf6l7ml\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/2hf6l7ml</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220412_014728-2hf6l7ml/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout"
      ],
      "metadata": {
        "id": "-dRkWNbc60m5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RNN & GRU"
      ],
      "metadata": {
        "id": "-UJ3kjycUw62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_type in [\"RNN\"]:\n",
        "    for dropout in [0.2,0.3,0.4]:\n",
        "            config['dim_embedding'] = 196\n",
        "            config['dropout'] = dropout\n",
        "            config['model_type'] = model_type\n",
        "            model = TranslationRNN(\n",
        "                config['n_tokens_src'],\n",
        "                config['n_tokens_tgt'],\n",
        "                config['dim_embedding'],\n",
        "                config['dim_hidden'],\n",
        "                config['n_layers'],\n",
        "                config['dropout'],\n",
        "                config['src_pad_idx'],\n",
        "                config['tgt_pad_idx'],\n",
        "                config['model_type'],\n",
        "            )\n",
        "            model.train()\n",
        "\n",
        "\n",
        "            #Replace the model to train here\n",
        "            config['optimizer'] = optim.Adam(\n",
        "                model.parameters(),\n",
        "                lr=config['lr'],\n",
        "                betas=config['betas'],\n",
        "            )\n",
        "\n",
        "            weight_classes = torch.ones(config['n_tokens_tgt'], dtype=torch.float)\n",
        "            weight_classes[config['tgt_vocab']['<unk>']] = 0.1  # Lower the importance of that class\n",
        "            config['loss'] = nn.CrossEntropyLoss(\n",
        "                weight=weight_classes,\n",
        "                ignore_index=config['tgt_pad_idx'],  # We do not have to learn those\n",
        "            )\n",
        "\n",
        "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "            with wandb.init(\n",
        "                    config=config,\n",
        "                    project='INF8225 - TP3',  # Title of your project\n",
        "                    group='Dropout RNN',  # In what group of runs do you want this run to be in?\n",
        "                    save_code=True,\n",
        "                    mode = 'online',\n",
        "                    name = model_type + \" dropout:\" + str(dropout)\n",
        "                ):\n",
        "                train_model(model, config)\n",
        "                wandb.log({\"bleu_score\":evaluate_blue_score(model)})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "459c0b06589141ab8cdbfcac2f011ab0",
            "276e312c7f2b433d9e0e6094c81707aa",
            "cdf7681941bb4a36aeb1554f1d656937",
            "2115b02e7b8446718d1bcbd6163001a2",
            "70c71154422642f8a190b4eb0d3f44b1",
            "c3fa2093d6214f10bd95bd0d4638a54f",
            "6bc51ed569bc48bc9dd23ba75629bdb2",
            "303f0aab342244899a79a5cdfafd48f3",
            "5619e98b8028444bbc5c9858d62e1644",
            "d2e5c39ba93b47cbacb6e7da791c2ba3",
            "0cd03ee5db414dec920f60de8f83b64f",
            "b8895d1e177c431a81d8385d310305e7",
            "0a1286898abc40b4a64089c1a9b8abc9",
            "29a056489f524ab29d436d64786e85f6",
            "76517e4d03a34567aa656f0e64de18e3",
            "f4685e3bb5a34866a7c2376e1cce6385"
          ]
        },
        "id": "qfEg7QnaU1BU",
        "outputId": "7a3ead7f-8b5a-44c6-b25b-cfe24eb00e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwittythemighty\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220412_030220-icshek5f</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/icshek5f\" target=\"_blank\">RNN dropout:0.2</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.85     top-1: 0.47    top-5: 0.66    top-10: 0.71\n",
            "Eval -    loss: 2.80     top-1: 0.47    top-5: 0.65    top-10: 0.71\n",
            "Here is my bicycle.\n",
            "Voici un moment.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 2.63     top-1: 0.49    top-5: 0.67    top-10: 0.74\n",
            "Eval -    loss: 2.56     top-1: 0.50    top-5: 0.68    top-10: 0.75\n",
            "I was detained.\n",
            "J'étais en sécurité.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 2.57     top-1: 0.51    top-5: 0.69    top-10: 0.75\n",
            "Eval -    loss: 2.44     top-1: 0.51    top-5: 0.70    top-10: 0.76\n",
            "Your lives will be spared if you surrender.\n",
            "Vos idées nous rendons tous.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 2.42     top-1: 0.52    top-5: 0.70    top-10: 0.78\n",
            "Eval -    loss: 2.37     top-1: 0.52    top-5: 0.71    top-10: 0.77\n",
            "Light travels faster than sound.\n",
            "Peu de personnes ont été tués.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 2.58     top-1: 0.50    top-5: 0.68    top-10: 0.74\n",
            "Eval -    loss: 2.33     top-1: 0.52    top-5: 0.71    top-10: 0.78\n",
            "It's recommended that you don't write your passwords down where others might see them.\n",
            "C'est tout ce que tu veux.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.440 MB of 0.440 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "459c0b06589141ab8cdbfcac2f011ab0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▄▆▇█</td></tr><tr><td>Validation - top-5</td><td>▁▄▆▇█</td></tr><tr><td>bleu_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>2.57943</td></tr><tr><td>Train - top-1</td><td>0.49538</td></tr><tr><td>Train - top-10</td><td>0.73947</td></tr><tr><td>Train - top-5</td><td>0.6843</td></tr><tr><td>Validation - loss</td><td>2.33455</td></tr><tr><td>Validation - top-1</td><td>0.52329</td></tr><tr><td>Validation - top-10</td><td>0.77807</td></tr><tr><td>Validation - top-5</td><td>0.71437</td></tr><tr><td>bleu_score</td><td>0.08652</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">RNN dropout:0.2</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/icshek5f\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/icshek5f</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220412_030220-icshek5f/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220412_031632-1lkdiajc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/1lkdiajc\" target=\"_blank\">RNN dropout:0.3</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.447 MB of 0.447 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5619e98b8028444bbc5c9858d62e1644"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▃▂▂▂▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▅▆▇▇████</td></tr><tr><td>Train - top-10</td><td>▁▅▆▇▇████</td></tr><tr><td>Train - top-5</td><td>▁▅▆▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>3.67701</td></tr><tr><td>Train - top-1</td><td>0.38734</td></tr><tr><td>Train - top-10</td><td>0.61926</td></tr><tr><td>Train - top-5</td><td>0.54986</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">RNN dropout:0.3</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/1lkdiajc\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/1lkdiajc</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220412_031632-1lkdiajc/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-a0375c04ff55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" dropout:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 ):\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"bleu_score\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mevaluate_blue_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-a32f9e84013b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, config)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformer"
      ],
      "metadata": {
        "id": "CgXu2ERlUtXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for dropout in [0.1,0.2,0.3,0.4]:\n",
        "    config[\"dim_embedding\"] = 196\n",
        "    config['n_heads'] = 4\n",
        "    model = TranslationTransformer(\n",
        "    config['n_tokens_src'],\n",
        "    config['n_tokens_tgt'],\n",
        "    config['n_heads'],\n",
        "    config['dim_embedding'],\n",
        "    config['dim_hidden'],\n",
        "    config['n_layers'],\n",
        "    config['dropout'],\n",
        "    config['src_pad_idx'],\n",
        "    config['tgt_pad_idx']\n",
        "    )\n",
        "    config['optimizer'] = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config['lr'],\n",
        "    betas=config['betas'],\n",
        "    )\n",
        "    weight_classes = torch.ones(config['n_tokens_tgt'], dtype=torch.float)\n",
        "    weight_classes[config['tgt_vocab']['<unk>']] = 0.1  # Lower the importance of that class\n",
        "    config['loss'] = nn.CrossEntropyLoss(weight=weight_classes,ignore_index=config['tgt_pad_idx'] )\n",
        "    with wandb.init(\n",
        "            config=config,\n",
        "            project='INF8225 - TP3',  # Title of your project\n",
        "            group='Transformer - Dropout',  \n",
        "            save_code=True,\n",
        "            mode = 'online',\n",
        "            name = \"Transformer with \"+ str(dropout)\n",
        "        ):\n",
        "        train_model(model, config)\n",
        "        wandb.log({\"bleu_score\":evaluate_blue_score(model)})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1963c928b99e4fdf842e3d0e27952059",
            "7487ffd9e3944244bce544cb96985251",
            "059982fd05b146569e2287a493221a77",
            "b5fb984111954ce0b840be0bd159b05f",
            "da02861d85a34dfc836e010cea0fb847",
            "6d573f90b6fb4a87b7bbd88b3817f9f4",
            "34f1e1fe98a14aa1818a2524cee41a19",
            "b2117e1628a644a29fa799bd728e2d7f",
            "f9bdf300e64b4d029ad074e8d7c43847",
            "7561b903854245e69f169355f1173d3c",
            "56c0c45eb5e34c5587b8a392a46136ca",
            "8009457d1d804b5ab71e221c1e329e9d",
            "fb276b0018aa4f88bbd550d1060835db",
            "f17b66fd8b604f3581827de57e9bba01",
            "ae8aa03565f349cab6229afab6070365",
            "8444e07b5b854e879a96e9538dd640f8",
            "475a3aa955be43288cadb14386de7ab6",
            "fc27e696c30e41768c79d1d8e4658980",
            "3010b310d4d34defbd562364f02730fb",
            "54413e6db35440ffb0d059ebaf4df1af",
            "dbaa30ee66784e52a847c3dbfe2d7a49",
            "8e6861c184c04502b0b87882580ba929",
            "08b19252dd3b4500a0f257817986bb0b",
            "32a49c94f3824e74b1f134e050bc184d",
            "a6c97c19ccba461b985ffcfe5820c4b0",
            "868f2c1b331f466b85ec200781736837",
            "5e3c0ab01c584f0ca2533805007d5e29",
            "61c9b477952642868937ebf789eb4ae9",
            "16cc3932febb44188a7fa552aef7f551",
            "98f17eb63d0f4a3d85c2e2a9b8641bda",
            "56d780e3aa304415932754535f4ff824",
            "0ee4f5fedd5a4152901f671c7c0a06aa"
          ]
        },
        "id": "I8pKS_qDEX9D",
        "outputId": "6293a7c4-0989-4902-cf13-4d7680ec3775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220412_020124-1pn4mu8l</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/1pn4mu8l\" target=\"_blank\">Transformer with 0.1</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.46     top-1: 0.56    top-5: 0.74    top-10: 0.80\n",
            "Eval -    loss: 2.15     top-1: 0.58    top-5: 0.77    top-10: 0.82\n",
            "Are you leaving?\n",
            "Es-tu ?\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.74     top-1: 0.65    top-5: 0.83    top-10: 0.86\n",
            "Eval -    loss: 1.72     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "It's sort of strange.\n",
            "C'est bizarre.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.67     top-1: 0.64    top-5: 0.84    top-10: 0.88\n",
            "Eval -    loss: 1.53     top-1: 0.67    top-5: 0.86    top-10: 0.89\n",
            "Let's start with the easy stuff.\n",
            "Commençons.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.57     top-1: 0.68    top-5: 0.87    top-10: 0.90\n",
            "Eval -    loss: 1.44     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "The king always wears a crown.\n",
            "Le roi porte toujours un roi.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.42     top-1: 0.67    top-5: 0.88    top-10: 0.92\n",
            "Eval -    loss: 1.34     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "We can't prove anything.\n",
            "Nous ne pouvons rien prouver.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.378 MB of 0.378 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1963c928b99e4fdf842e3d0e27952059"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇██████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▇▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▆▇█</td></tr><tr><td>bleu_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.41811</td></tr><tr><td>Train - top-1</td><td>0.67042</td></tr><tr><td>Train - top-10</td><td>0.91893</td></tr><tr><td>Train - top-5</td><td>0.88184</td></tr><tr><td>Validation - loss</td><td>1.34466</td></tr><tr><td>Validation - top-1</td><td>0.70089</td></tr><tr><td>Validation - top-10</td><td>0.90972</td></tr><tr><td>Validation - top-5</td><td>0.8784</td></tr><tr><td>bleu_score</td><td>0.24115</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Transformer with 0.1</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/1pn4mu8l\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/1pn4mu8l</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220412_020124-1pn4mu8l/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220412_021330-1z7ygszc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/1z7ygszc\" target=\"_blank\">Transformer with 0.2</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.34     top-1: 0.53    top-5: 0.75    top-10: 0.81\n",
            "Eval -    loss: 2.14     top-1: 0.58    top-5: 0.77    top-10: 0.82\n",
            "He might possibly say something ambiguous again.\n",
            "Il pourrait dire quelque chose à nouveau.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.79     top-1: 0.62    top-5: 0.82    top-10: 0.87\n",
            "Eval -    loss: 1.72     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "He said it as a joke.\n",
            "Il a dit que ça.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.55     top-1: 0.68    top-5: 0.87    top-10: 0.90\n",
            "Eval -    loss: 1.54     top-1: 0.67    top-5: 0.85    top-10: 0.89\n",
            "She liked tennis and became a tennis coach.\n",
            "Elle est devenu médecin et au tennis.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.40     top-1: 0.69    top-5: 0.88    top-10: 0.91\n",
            "Eval -    loss: 1.42     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "Come on. You're not that old.\n",
            "Venez ça.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.44     top-1: 0.68    top-5: 0.87    top-10: 0.91\n",
            "Eval -    loss: 1.35     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Three of them were hospitalized.\n",
            "Trois de eux étaient hospitalisé.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.391 MB of 0.391 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9bdf300e64b4d029ad074e8d7c43847"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▄▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▆▇█</td></tr><tr><td>bleu_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.44293</td></tr><tr><td>Train - top-1</td><td>0.68447</td></tr><tr><td>Train - top-10</td><td>0.90925</td></tr><tr><td>Train - top-5</td><td>0.8737</td></tr><tr><td>Validation - loss</td><td>1.34546</td></tr><tr><td>Validation - top-1</td><td>0.70121</td></tr><tr><td>Validation - top-10</td><td>0.91094</td></tr><tr><td>Validation - top-5</td><td>0.87874</td></tr><tr><td>bleu_score</td><td>0.25037</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Transformer with 0.2</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/1z7ygszc\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/1z7ygszc</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220412_021330-1z7ygszc/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220412_022537-qgc0t2m9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/qgc0t2m9\" target=\"_blank\">Transformer with 0.3</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.34     top-1: 0.55    top-5: 0.75    top-10: 0.80\n",
            "Eval -    loss: 2.16     top-1: 0.58    top-5: 0.77    top-10: 0.82\n",
            "It is more blessed to give than to receive.\n",
            "C'est plus grande que personne.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.96     top-1: 0.61    top-5: 0.81    top-10: 0.86\n",
            "Eval -    loss: 1.73     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "Tom wants to be strong.\n",
            "Tom veut être fort.\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.73     top-1: 0.66    top-5: 0.84    top-10: 0.87\n",
            "Eval -    loss: 1.55     top-1: 0.67    top-5: 0.85    top-10: 0.89\n",
            "I had a good night's sleep.\n",
            "J'ai eu une bonne nuit.\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.48     top-1: 0.68    top-5: 0.87    top-10: 0.90\n",
            "Eval -    loss: 1.43     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "You need to work faster.\n",
            "Vous devez travailler plus vite.\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.39     top-1: 0.68    top-5: 0.88    top-10: 0.92\n",
            "Eval -    loss: 1.36     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "If you push this button, the door will open.\n",
            "Si tu pars sur la porte, tu vas ouvrir.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.402 MB of 0.402 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "475a3aa955be43288cadb14386de7ab6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▆▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▆▇█</td></tr><tr><td>bleu_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.39318</td></tr><tr><td>Train - top-1</td><td>0.68338</td></tr><tr><td>Train - top-10</td><td>0.9169</td></tr><tr><td>Train - top-5</td><td>0.87831</td></tr><tr><td>Validation - loss</td><td>1.35923</td></tr><tr><td>Validation - top-1</td><td>0.69756</td></tr><tr><td>Validation - top-10</td><td>0.90955</td></tr><tr><td>Validation - top-5</td><td>0.87734</td></tr><tr><td>bleu_score</td><td>0.21948</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Transformer with 0.3</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/qgc0t2m9\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/qgc0t2m9</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220412_022537-qgc0t2m9/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220412_023742-1z73zw0l</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/1z73zw0l\" target=\"_blank\">Transformer with 0.4</a></strong> to <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 5 epochs, using cuda.\n",
            "\n",
            "Epoch 1\n",
            "Train -   loss: 2.48     top-1: 0.53    top-5: 0.74    top-10: 0.79\n",
            "Eval -    loss: 2.17     top-1: 0.58    top-5: 0.77    top-10: 0.81\n",
            "He doesn't know what he's talking about.\n",
            "Il ne sait pas quoi dire.\n",
            "\n",
            "Epoch 2\n",
            "Train -   loss: 1.95     top-1: 0.63    top-5: 0.80    top-10: 0.85\n",
            "Eval -    loss: 1.74     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "What is your opinion on school uniforms?\n",
            "Quel est votre opinion ?\n",
            "\n",
            "Epoch 3\n",
            "Train -   loss: 1.78     top-1: 0.64    top-5: 0.83    top-10: 0.87\n",
            "Eval -    loss: 1.55     top-1: 0.67    top-5: 0.85    top-10: 0.89\n",
            "Do you mind if I stay here?\n",
            "Voyez-vous un inconvénient à ce que je reste ici ?\n",
            "\n",
            "Epoch 4\n",
            "Train -   loss: 1.50     top-1: 0.68    top-5: 0.87    top-10: 0.90\n",
            "Eval -    loss: 1.43     top-1: 0.69    top-5: 0.87    top-10: 0.90\n",
            "Why didn't you tell this to the police?\n",
            "Pourquoi n'avez-vous pas dit cette police ?\n",
            "\n",
            "Epoch 5\n",
            "Train -   loss: 1.45     top-1: 0.67    top-5: 0.86    top-10: 0.90\n",
            "Eval -    loss: 1.36     top-1: 0.70    top-5: 0.88    top-10: 0.91\n",
            "Must I hurry?\n",
            "Ai-je l'air pressé ?\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.414 MB of 0.414 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6c97c19ccba461b985ffcfe5820c4b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train - top-1</td><td>▁▃▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Train - top-10</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>Train - top-5</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>Validation - loss</td><td>█▄▃▂▁</td></tr><tr><td>Validation - top-1</td><td>▁▄▆▇█</td></tr><tr><td>Validation - top-10</td><td>▁▅▇▇█</td></tr><tr><td>Validation - top-5</td><td>▁▅▆▇█</td></tr><tr><td>bleu_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train - loss</td><td>1.45272</td></tr><tr><td>Train - top-1</td><td>0.6731</td></tr><tr><td>Train - top-10</td><td>0.90333</td></tr><tr><td>Train - top-5</td><td>0.86023</td></tr><tr><td>Validation - loss</td><td>1.36062</td></tr><tr><td>Validation - top-1</td><td>0.69929</td></tr><tr><td>Validation - top-10</td><td>0.90843</td></tr><tr><td>Validation - top-5</td><td>0.877</td></tr><tr><td>bleu_score</td><td>0.24553</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Transformer with 0.4</strong>: <a href=\"https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/1z73zw0l\" target=\"_blank\">https://wandb.ai/wittythemighty/INF8225%20-%20TP3/runs/1z73zw0l</a><br/>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220412_023742-1z73zw0l/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": " INF8225 - TP3 - 1948612 -1949837 (experiments).ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f763af245f6c4450bd2a5ea079d598d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b34abb9b92ed43279ffa1ee70a7357e2",
              "IPY_MODEL_1bb59ac705a1400f940b246095711ffb"
            ],
            "layout": "IPY_MODEL_67ac515c98e84bff9f98ba5d84b1a687"
          }
        },
        "b34abb9b92ed43279ffa1ee70a7357e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1daf2c3b02646eda84ba8a9ef9a31df",
            "placeholder": "​",
            "style": "IPY_MODEL_db5c960935b54746812aee44ac0c8ac6",
            "value": "0.478 MB of 0.478 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "1bb59ac705a1400f940b246095711ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_090e3ebc7f9144099e67bf04dfbc73bb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4e9cec2424b4eb1a3b5b88bfb040982",
            "value": 1
          }
        },
        "67ac515c98e84bff9f98ba5d84b1a687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1daf2c3b02646eda84ba8a9ef9a31df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db5c960935b54746812aee44ac0c8ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "090e3ebc7f9144099e67bf04dfbc73bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4e9cec2424b4eb1a3b5b88bfb040982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4df2676466f24e7bb4395581ea19ac67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b31687a101e84e7e8db4d8aed7283f63",
              "IPY_MODEL_527aa8ae789c4244814e54fd989c07ec"
            ],
            "layout": "IPY_MODEL_65255b7d1bcf46dca09fa742cadbad64"
          }
        },
        "b31687a101e84e7e8db4d8aed7283f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb0daa906ca4f9eaf2e4997d563359d",
            "placeholder": "​",
            "style": "IPY_MODEL_3e0e5ade65ee4d7b81bc037b19efe2d7",
            "value": "0.490 MB of 0.490 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "527aa8ae789c4244814e54fd989c07ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af6762c918324791a710c108fe84f866",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53203386db6140e6aabe2770c39b833f",
            "value": 1
          }
        },
        "65255b7d1bcf46dca09fa742cadbad64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eb0daa906ca4f9eaf2e4997d563359d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e0e5ade65ee4d7b81bc037b19efe2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af6762c918324791a710c108fe84f866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53203386db6140e6aabe2770c39b833f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c77aca43269c444ea232eb852fb0255c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22715b7ebe7c442ab80043cbf53e65cc",
              "IPY_MODEL_03dd9450de02483680ce6d67455b7646"
            ],
            "layout": "IPY_MODEL_4125b2a384f941eca8b97dee0b06b206"
          }
        },
        "22715b7ebe7c442ab80043cbf53e65cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d78e1969603745f09fe31cf14bc52307",
            "placeholder": "​",
            "style": "IPY_MODEL_829ed0d87ea840d7a3be9de674e68c9c",
            "value": "0.501 MB of 0.501 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "03dd9450de02483680ce6d67455b7646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d83fd14ea8143758d415bdb95b3dd9e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6ffc0355a4240fba98d9eba46c11672",
            "value": 1
          }
        },
        "4125b2a384f941eca8b97dee0b06b206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d78e1969603745f09fe31cf14bc52307": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "829ed0d87ea840d7a3be9de674e68c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d83fd14ea8143758d415bdb95b3dd9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6ffc0355a4240fba98d9eba46c11672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfb75821be6648a5b64825c0adafd6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49996d04a0c5454ca53ac0d9a8c7a2c1",
              "IPY_MODEL_9367888f4b414d829edad7f7df3bec6f"
            ],
            "layout": "IPY_MODEL_57fa10f5ea85447b960c4dd3de0ec3f0"
          }
        },
        "49996d04a0c5454ca53ac0d9a8c7a2c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a99863768e24872973f200a4adc6eb5",
            "placeholder": "​",
            "style": "IPY_MODEL_7cdb95624d4f435ebbb13fcb88f1a127",
            "value": "0.513 MB of 0.513 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "9367888f4b414d829edad7f7df3bec6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ed5d5c53e24e9fa34907c51a5a16e7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb1022b693cb444191a49434c0fae9c8",
            "value": 1
          }
        },
        "57fa10f5ea85447b960c4dd3de0ec3f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a99863768e24872973f200a4adc6eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cdb95624d4f435ebbb13fcb88f1a127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4ed5d5c53e24e9fa34907c51a5a16e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb1022b693cb444191a49434c0fae9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0480313ab8c347da9448c91fc3206352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efe8ac50436b4788a13bbc0e07733092",
              "IPY_MODEL_1d718c20d10948bfbd46dbca31067233"
            ],
            "layout": "IPY_MODEL_ef8e797ba12748a789a71f1d420ca278"
          }
        },
        "efe8ac50436b4788a13bbc0e07733092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64b638506bfc45c8a57f9477bc5b5acf",
            "placeholder": "​",
            "style": "IPY_MODEL_8679de21d94449a9abb3a603ae25eecc",
            "value": "0.526 MB of 0.526 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "1d718c20d10948bfbd46dbca31067233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8ba57fbd0a447609ef09b0f026118e5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b18eb3938f9c4c45a756c871ef136f9c",
            "value": 1
          }
        },
        "ef8e797ba12748a789a71f1d420ca278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b638506bfc45c8a57f9477bc5b5acf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8679de21d94449a9abb3a603ae25eecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8ba57fbd0a447609ef09b0f026118e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b18eb3938f9c4c45a756c871ef136f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee11e7173a78439d957e9243c787bb4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3e8a4d68bdd444ba4c2323b328f7383",
              "IPY_MODEL_4b18623eb7484997a22ac2dd022b2d70"
            ],
            "layout": "IPY_MODEL_9976b7e5f37e4a13b56177d990002e72"
          }
        },
        "d3e8a4d68bdd444ba4c2323b328f7383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c8e299b2b74455ea1160fce5d17fc8f",
            "placeholder": "​",
            "style": "IPY_MODEL_468d51a185fe46c8a734d11cadf33961",
            "value": "0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "4b18623eb7484997a22ac2dd022b2d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c02966f8919c4334bd9a680993cb8a82",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db35367d3ab74b80bd49db331f5bd797",
            "value": 1
          }
        },
        "9976b7e5f37e4a13b56177d990002e72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c8e299b2b74455ea1160fce5d17fc8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "468d51a185fe46c8a734d11cadf33961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c02966f8919c4334bd9a680993cb8a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db35367d3ab74b80bd49db331f5bd797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3ed53664c2d404c99898497431494f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec8e927886014db487c3e8dbdc4b7362",
              "IPY_MODEL_2e1d718d53654990b4ad5aecfd2d2a79"
            ],
            "layout": "IPY_MODEL_468d69895f304b88b964b528ed19e0f6"
          }
        },
        "ec8e927886014db487c3e8dbdc4b7362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2296a31bdb3b46639c25df7bedff9064",
            "placeholder": "​",
            "style": "IPY_MODEL_1fe03f97c7834bbb8d1a97f268201308",
            "value": "0.442 MB of 0.442 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "2e1d718d53654990b4ad5aecfd2d2a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74509423b4ac4c85ae9f8f68d6446b34",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94fe720bf5b44694b4aad1de22a4f300",
            "value": 1
          }
        },
        "468d69895f304b88b964b528ed19e0f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2296a31bdb3b46639c25df7bedff9064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fe03f97c7834bbb8d1a97f268201308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74509423b4ac4c85ae9f8f68d6446b34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94fe720bf5b44694b4aad1de22a4f300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c46332c7e13f4c299b863161744c3e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce450584520541ee9fbd5e50c339ac87",
              "IPY_MODEL_7fe1bdcf116449b99ffcf36773724194"
            ],
            "layout": "IPY_MODEL_50c5e0180a564d56b4ea7b8315e42f8c"
          }
        },
        "ce450584520541ee9fbd5e50c339ac87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a181949177e43db9b5a73a1fd2d7b39",
            "placeholder": "​",
            "style": "IPY_MODEL_24d0e9d5b9394d84b6c9b1dbf12ced42",
            "value": "0.454 MB of 0.454 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "7fe1bdcf116449b99ffcf36773724194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1239f709d9e9489b92087e3cc9e02dd6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7489ca3405f442a0973f0012b8148dbe",
            "value": 1
          }
        },
        "50c5e0180a564d56b4ea7b8315e42f8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a181949177e43db9b5a73a1fd2d7b39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24d0e9d5b9394d84b6c9b1dbf12ced42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1239f709d9e9489b92087e3cc9e02dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7489ca3405f442a0973f0012b8148dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e592031de9b94c76af11d03c9507434a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_803ca61e9b344561a34b001dc404eea8",
              "IPY_MODEL_fd0cab687007439cb11aa1f9b68fbb37"
            ],
            "layout": "IPY_MODEL_b5777eecf7c746208b73a976a98b5ba0"
          }
        },
        "803ca61e9b344561a34b001dc404eea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f964857f53644b486f5a0f499f12ffa",
            "placeholder": "​",
            "style": "IPY_MODEL_dce4ad9220d6451096d655e34c9ed6da",
            "value": "0.465 MB of 0.465 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "fd0cab687007439cb11aa1f9b68fbb37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fe649f48f16443491b28fac4b907189",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8328b3035cb24325bdb774c303c3c719",
            "value": 1
          }
        },
        "b5777eecf7c746208b73a976a98b5ba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f964857f53644b486f5a0f499f12ffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce4ad9220d6451096d655e34c9ed6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fe649f48f16443491b28fac4b907189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8328b3035cb24325bdb774c303c3c719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f3c29a65a0f44b2af4df837bf6638e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_798fc758e1804ecd8a462f8919e3386a",
              "IPY_MODEL_4329dc6fb0ab416db36d307bba7071f5"
            ],
            "layout": "IPY_MODEL_d366e38235974ae2be2e54af18b7130a"
          }
        },
        "798fc758e1804ecd8a462f8919e3386a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44f12917a6de4d89bac2737c1dc05cb7",
            "placeholder": "​",
            "style": "IPY_MODEL_af9a210c76894320927c6db6725868bc",
            "value": "0.477 MB of 0.477 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "4329dc6fb0ab416db36d307bba7071f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6268c0d2380f49bca42d094fab4a467c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b5560c94b874e44b0d3a030a5478124",
            "value": 1
          }
        },
        "d366e38235974ae2be2e54af18b7130a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44f12917a6de4d89bac2737c1dc05cb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af9a210c76894320927c6db6725868bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6268c0d2380f49bca42d094fab4a467c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b5560c94b874e44b0d3a030a5478124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "459c0b06589141ab8cdbfcac2f011ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_276e312c7f2b433d9e0e6094c81707aa",
              "IPY_MODEL_cdf7681941bb4a36aeb1554f1d656937"
            ],
            "layout": "IPY_MODEL_2115b02e7b8446718d1bcbd6163001a2"
          }
        },
        "276e312c7f2b433d9e0e6094c81707aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70c71154422642f8a190b4eb0d3f44b1",
            "placeholder": "​",
            "style": "IPY_MODEL_c3fa2093d6214f10bd95bd0d4638a54f",
            "value": "0.565 MB of 0.565 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "cdf7681941bb4a36aeb1554f1d656937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bc51ed569bc48bc9dd23ba75629bdb2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_303f0aab342244899a79a5cdfafd48f3",
            "value": 1
          }
        },
        "2115b02e7b8446718d1bcbd6163001a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70c71154422642f8a190b4eb0d3f44b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3fa2093d6214f10bd95bd0d4638a54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bc51ed569bc48bc9dd23ba75629bdb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "303f0aab342244899a79a5cdfafd48f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5619e98b8028444bbc5c9858d62e1644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2e5c39ba93b47cbacb6e7da791c2ba3",
              "IPY_MODEL_0cd03ee5db414dec920f60de8f83b64f"
            ],
            "layout": "IPY_MODEL_b8895d1e177c431a81d8385d310305e7"
          }
        },
        "d2e5c39ba93b47cbacb6e7da791c2ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a1286898abc40b4a64089c1a9b8abc9",
            "placeholder": "​",
            "style": "IPY_MODEL_29a056489f524ab29d436d64786e85f6",
            "value": "0.570 MB of 0.570 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "0cd03ee5db414dec920f60de8f83b64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76517e4d03a34567aa656f0e64de18e3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4685e3bb5a34866a7c2376e1cce6385",
            "value": 1
          }
        },
        "b8895d1e177c431a81d8385d310305e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a1286898abc40b4a64089c1a9b8abc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a056489f524ab29d436d64786e85f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76517e4d03a34567aa656f0e64de18e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4685e3bb5a34866a7c2376e1cce6385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1963c928b99e4fdf842e3d0e27952059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7487ffd9e3944244bce544cb96985251",
              "IPY_MODEL_059982fd05b146569e2287a493221a77"
            ],
            "layout": "IPY_MODEL_b5fb984111954ce0b840be0bd159b05f"
          }
        },
        "7487ffd9e3944244bce544cb96985251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da02861d85a34dfc836e010cea0fb847",
            "placeholder": "​",
            "style": "IPY_MODEL_6d573f90b6fb4a87b7bbd88b3817f9f4",
            "value": "0.492 MB of 0.492 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "059982fd05b146569e2287a493221a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34f1e1fe98a14aa1818a2524cee41a19",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2117e1628a644a29fa799bd728e2d7f",
            "value": 1
          }
        },
        "b5fb984111954ce0b840be0bd159b05f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da02861d85a34dfc836e010cea0fb847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d573f90b6fb4a87b7bbd88b3817f9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34f1e1fe98a14aa1818a2524cee41a19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2117e1628a644a29fa799bd728e2d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9bdf300e64b4d029ad074e8d7c43847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7561b903854245e69f169355f1173d3c",
              "IPY_MODEL_56c0c45eb5e34c5587b8a392a46136ca"
            ],
            "layout": "IPY_MODEL_8009457d1d804b5ab71e221c1e329e9d"
          }
        },
        "7561b903854245e69f169355f1173d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb276b0018aa4f88bbd550d1060835db",
            "placeholder": "​",
            "style": "IPY_MODEL_f17b66fd8b604f3581827de57e9bba01",
            "value": "0.504 MB of 0.504 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "56c0c45eb5e34c5587b8a392a46136ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae8aa03565f349cab6229afab6070365",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8444e07b5b854e879a96e9538dd640f8",
            "value": 1
          }
        },
        "8009457d1d804b5ab71e221c1e329e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb276b0018aa4f88bbd550d1060835db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17b66fd8b604f3581827de57e9bba01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae8aa03565f349cab6229afab6070365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8444e07b5b854e879a96e9538dd640f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "475a3aa955be43288cadb14386de7ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc27e696c30e41768c79d1d8e4658980",
              "IPY_MODEL_3010b310d4d34defbd562364f02730fb"
            ],
            "layout": "IPY_MODEL_54413e6db35440ffb0d059ebaf4df1af"
          }
        },
        "fc27e696c30e41768c79d1d8e4658980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbaa30ee66784e52a847c3dbfe2d7a49",
            "placeholder": "​",
            "style": "IPY_MODEL_8e6861c184c04502b0b87882580ba929",
            "value": "0.516 MB of 0.516 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "3010b310d4d34defbd562364f02730fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08b19252dd3b4500a0f257817986bb0b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32a49c94f3824e74b1f134e050bc184d",
            "value": 1
          }
        },
        "54413e6db35440ffb0d059ebaf4df1af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbaa30ee66784e52a847c3dbfe2d7a49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e6861c184c04502b0b87882580ba929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08b19252dd3b4500a0f257817986bb0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a49c94f3824e74b1f134e050bc184d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6c97c19ccba461b985ffcfe5820c4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_868f2c1b331f466b85ec200781736837",
              "IPY_MODEL_5e3c0ab01c584f0ca2533805007d5e29"
            ],
            "layout": "IPY_MODEL_61c9b477952642868937ebf789eb4ae9"
          }
        },
        "868f2c1b331f466b85ec200781736837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16cc3932febb44188a7fa552aef7f551",
            "placeholder": "​",
            "style": "IPY_MODEL_98f17eb63d0f4a3d85c2e2a9b8641bda",
            "value": "0.528 MB of 0.528 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "5e3c0ab01c584f0ca2533805007d5e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56d780e3aa304415932754535f4ff824",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ee4f5fedd5a4152901f671c7c0a06aa",
            "value": 1
          }
        },
        "61c9b477952642868937ebf789eb4ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16cc3932febb44188a7fa552aef7f551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f17eb63d0f4a3d85c2e2a9b8641bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56d780e3aa304415932754535f4ff824": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee4f5fedd5a4152901f671c7c0a06aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}